{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gayun99/dacon_competition/blob/main/%EC%9E%A1%EC%BC%80%EC%96%B4_lgb_%2B_xgb_%2B_cat_stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgYmKUgGtW7s",
        "outputId": "6949e370-cf6f-460a-ee23-68406ab2add1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyWA1ke6vyLY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQEVNXoawCMl",
        "outputId": "6edc7887-d624-4bd9-9342-1899cc716662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 35)\n",
            "test_data.shape:  (46404, 34)\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv(\"/content/drive/MyDrive/jobcare/data/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/jobcare/data/test.csv\")\n",
        "\n",
        "d_code = pd.read_csv('/content/drive/MyDrive/jobcare/data/속성_D_코드.csv', index_col=0).T.to_dict()\n",
        "h_code = pd.read_csv('/content/drive/MyDrive/jobcare/data/속성_H_코드.csv', index_col=0).T.to_dict()\n",
        "l_code = pd.read_csv('/content/drive/MyDrive/jobcare/data/속성_L_코드.csv', index_col=0).T.to_dict()\n",
        "\n",
        "print(\"train_data.shape: \", train_data.shape)\n",
        "print(\"test_data.shape: \", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FidFOylPzR5l"
      },
      "outputs": [],
      "source": [
        "#train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dHJPtFmzgyH",
        "outputId": "88d10bd7-45e0-48db-dc0c-9f9921ca6104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:  (501951, 63)\n",
            "test_data.shape:  (46404, 62)\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict\n",
        "def add_code(\n",
        "    df: pd.DataFrame,\n",
        "    d_code: Dict[int, Dict[str, int]], \n",
        "    h_code: Dict[int, Dict[str, int]], \n",
        "    l_code: Dict[int, Dict[str, int]],\n",
        ") -> pd.DataFrame:\n",
        "    \n",
        "    # Copy input data\n",
        "    df = df.copy()   \n",
        "\n",
        "    # D Code\n",
        "    df['person_prefer_d_1_n'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_1_s'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_1_m'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_1_l'] = df['person_prefer_d_1'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_2_n'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_2_s'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_2_m'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_2_l'] = df['person_prefer_d_2'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['person_prefer_d_3_n'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['person_prefer_d_3_s'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['person_prefer_d_3_m'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['person_prefer_d_3_l'] = df['person_prefer_d_3'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    df['contents_attribute_d_n'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 세분류코드'])\n",
        "    df['contents_attribute_d_s'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 소분류코드'])\n",
        "    df['contents_attribute_d_m'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 중분류코드'])\n",
        "    df['contents_attribute_d_l'] = df['contents_attribute_d'].apply(lambda x: d_code[x]['속성 D 대분류코드'])\n",
        "\n",
        "    # H Code\n",
        "    df['person_prefer_h_1_l'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_1_m'] = df['person_prefer_h_1'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    \n",
        "    df['person_prefer_h_2_l'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_2_m'] = df['person_prefer_h_2'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "    \n",
        "    df['person_prefer_h_3_l'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['person_prefer_h_3_m'] = df['person_prefer_h_3'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    df['contents_attribute_h_l'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 대분류코드'])\n",
        "    df['contents_attribute_h_m'] = df['contents_attribute_h'].apply(lambda x: h_code[x]['속성 H 중분류코드'])\n",
        "\n",
        "    # L Code\n",
        "    df['contents_attribute_l_n'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 세분류코드'])\n",
        "    df['contents_attribute_l_s'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 소분류코드'])\n",
        "    df['contents_attribute_l_m'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 중분류코드'])\n",
        "    df['contents_attribute_l_l'] = df['contents_attribute_l'].apply(lambda x: l_code[x]['속성 L 대분류코드'])\n",
        "    \n",
        "    return df\n",
        "\n",
        "train_data = add_code(train_data, d_code, h_code, l_code)\n",
        "test_data = add_code(test_data, d_code, h_code, l_code)\n",
        "print(\"train_data.shape: \", train_data.shape)\n",
        "print(\"test_data.shape: \", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIMdlxtxCeD3"
      },
      "outputs": [],
      "source": [
        "train_data['dt']= pd.to_datetime(train_data['contents_open_dt'], format = \"%Y-%m-%d %H:%M:%S\")\n",
        "test_data['dt']= pd.to_datetime(test_data['contents_open_dt'], format = \"%Y-%m-%d %H:%M:%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1izbZW3yDZgN"
      },
      "outputs": [],
      "source": [
        "# def preprocessing_contents_open_dt(data):\n",
        "#     data['contents_open_dt'] = data['contents_open_dt'].astype('str')\n",
        "#     DATE = data['contents_open_dt'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
        "    \n",
        "#     DATE = pd.DataFrame(DATE)\n",
        "#     DATE = DATE.rename(columns = {'contents_open_dt': 'date'})\n",
        "    \n",
        "#     DATE['Y'] = DATE['date'].apply(lambda x: x.timetuple()[0])\n",
        "#     DATE['M'] = DATE['date'].apply(lambda x: x.timetuple()[1])\n",
        "#     DATE['D'] = DATE['date'].apply(lambda x: x.timetuple()[2])\n",
        "#     DATE['id'] = data['id']\n",
        "    \n",
        "#     data = data.merge(DATE, on = 'id', how = 'left')\n",
        "#     data = data.drop(columns = ['date', 'contents_open_dt'])\n",
        "#     return data\n",
        "\n",
        "# train_data = preprocessing_contents_open_dt(train_data)\n",
        "# test_data = preprocessing_contents_open_dt(test_data)\n",
        "\n",
        "# # 안전하게 확인하고 넘어 갑시다. \n",
        "# train_data_labels = train_data['target']\n",
        "# train_data, test_data = train_data.align(test_data, join = 'inner', axis = 1)\n",
        "# train_data['target'] = train_data_labels\n",
        "# print(\"train_data.shape: \", train_data.shape)\n",
        "# print(\"test_data.shape: \", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlbBPuXkEN7Y"
      },
      "outputs": [],
      "source": [
        "#train_data['Y'].value_counts()\n",
        "#train_data['M'].value_counts()\n",
        "#train_data['D'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF3Q9E2JFpEH"
      },
      "outputs": [],
      "source": [
        "job_data = train_data.copy()\n",
        "job_data_test = test_data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VxguJ4SFs73",
        "outputId": "ecc373e0-1daf-42a7-b480-37178861247a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int64             56\n",
              "bool               6\n",
              "object             1\n",
              "datetime64[ns]     1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "job_data.dtypes.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K47lPpb4GTKJ"
      },
      "outputs": [],
      "source": [
        "#job_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1KT5WZMG3Q5",
        "outputId": "6917d151-ea5b-4c8f-fc26-0f7bf7dfd62f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                        501951\n",
              "person_attribute_a             2\n",
              "person_attribute_a_1           8\n",
              "person_attribute_b             6\n",
              "person_prefer_c                5\n",
              "person_prefer_d_1           1093\n",
              "person_prefer_d_2           1081\n",
              "person_prefer_d_3           1043\n",
              "person_prefer_e               12\n",
              "person_prefer_f                1\n",
              "person_prefer_g                1\n",
              "person_prefer_h_1            279\n",
              "person_prefer_h_2            279\n",
              "person_prefer_h_3            279\n",
              "contents_attribute_i           3\n",
              "contents_attribute_a           3\n",
              "contents_attribute_j_1         9\n",
              "contents_attribute_j           2\n",
              "contents_attribute_c           4\n",
              "contents_attribute_k           2\n",
              "contents_attribute_l        1752\n",
              "contents_attribute_d        1065\n",
              "contents_attribute_m           5\n",
              "contents_attribute_e          12\n",
              "contents_attribute_h         250\n",
              "person_rn                 300177\n",
              "contents_rn               283359\n",
              "target                         2\n",
              "person_prefer_d_1_n          443\n",
              "person_prefer_d_1_s          137\n",
              "person_prefer_d_1_m           36\n",
              "person_prefer_d_1_l           11\n",
              "person_prefer_d_2_n          435\n",
              "person_prefer_d_2_s          137\n",
              "person_prefer_d_2_m           36\n",
              "person_prefer_d_2_l           11\n",
              "person_prefer_d_3_n          420\n",
              "person_prefer_d_3_s          136\n",
              "person_prefer_d_3_m           36\n",
              "person_prefer_d_3_l           11\n",
              "contents_attribute_d_n       431\n",
              "contents_attribute_d_s       137\n",
              "contents_attribute_d_m        36\n",
              "contents_attribute_d_l        11\n",
              "person_prefer_h_1_l           19\n",
              "person_prefer_h_1_m          246\n",
              "person_prefer_h_2_l           19\n",
              "person_prefer_h_2_m          246\n",
              "person_prefer_h_3_l           19\n",
              "person_prefer_h_3_m          246\n",
              "contents_attribute_h_l        17\n",
              "contents_attribute_h_m       228\n",
              "contents_attribute_l_n       736\n",
              "contents_attribute_l_s       305\n",
              "contents_attribute_l_m        79\n",
              "contents_attribute_l_l        21\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "job_data.select_dtypes('int64').apply(pd.Series.nunique, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZPZoQPl9X1S"
      },
      "outputs": [],
      "source": [
        "# contents rn과 선지(속성)간의 상관관계?\n",
        "# 날짜 추가할지\n",
        "# person_rn 추가할지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajv1XG0ijchN"
      },
      "outputs": [],
      "source": [
        "# ! pip install pycaret[full]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0J1-4nRk4E8"
      },
      "outputs": [],
      "source": [
        "drop = ['id','person_prefer_f', 'person_prefer_g', 'contents_open_dt', 'dt', 'person_rn', 'contents_rn' ]\n",
        "# contents_rn 때문에 메모리에러 나는거같아서 제외시켜봄"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JFY3wOCodOD"
      },
      "outputs": [],
      "source": [
        "train = job_data.drop(drop,axis=1)\n",
        "test = job_data_test.drop(drop,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7K3MqvcphKc"
      },
      "outputs": [],
      "source": [
        "traina = train.select_dtypes('bool')\n",
        "trainb = train.select_dtypes('int64')\n",
        "# trainb= trainb.astype(dtype='int32') #데이터 줄일라고 int64에서 int32으로 변경\n",
        "#train = pd.concat([traina,trainb],axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzYl1DaakdZP",
        "outputId": "88229c30-ebe5-453d-b1a8-97e39ca8f620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['person_prefer_d_1_m', 'person_prefer_e', 'contents_attribute_j_1', 'person_attribute_b', 'person_attribute_a', 'person_prefer_h_2_l', 'contents_attribute_c', 'contents_attribute_a', 'contents_attribute_d_l', 'person_prefer_h_3_l', 'contents_attribute_e', 'contents_attribute_m', 'person_prefer_h_1_l', 'contents_attribute_d_m', 'person_prefer_d_3_l', 'contents_attribute_i', 'person_prefer_d_2_l', 'person_prefer_d_2_m', 'contents_attribute_l_l', 'contents_attribute_k', 'contents_attribute_j', 'person_attribute_a_1', 'person_prefer_d_1_l', 'person_prefer_c', 'contents_attribute_h_l', 'person_prefer_d_3_m'] 26\n"
          ]
        }
      ],
      "source": [
        "cat_features = trainb.columns[ (trainb.nunique() >= 2) & (trainb.nunique() < 50) ].tolist() #bool 제외한 trainb에서 categorical feature추출\n",
        "target = ['target']\n",
        "cat_features = list(set(cat_features) - set(target)) #target제외\n",
        "print(cat_features, len(cat_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk3vreFyphKe",
        "outputId": "ff80ea8c-7f0d-4032-bd7d-d119db3b880b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['person_prefer_d_1', 'person_prefer_d_2', 'person_prefer_d_3', 'person_prefer_h_1', 'person_prefer_h_2', 'person_prefer_h_3', 'contents_attribute_l', 'contents_attribute_d', 'contents_attribute_h', 'person_prefer_d_1_n', 'person_prefer_d_1_s', 'person_prefer_d_2_n', 'person_prefer_d_2_s', 'person_prefer_d_3_n', 'person_prefer_d_3_s', 'contents_attribute_d_n', 'contents_attribute_d_s', 'person_prefer_h_1_m', 'person_prefer_h_2_m', 'person_prefer_h_3_m', 'contents_attribute_h_m', 'contents_attribute_l_n', 'contents_attribute_l_s', 'contents_attribute_l_m'] 24\n"
          ]
        }
      ],
      "source": [
        "high_cardinality_features = trainb.columns[ trainb.nunique() >= 50 ].tolist() # 50개 이상인건 high cardinality feature로 변경\n",
        "print(high_cardinality_features , len(high_cardinality_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2xh-86SphKe"
      },
      "outputs": [],
      "source": [
        "cate = list(set().union(cat_features, high_cardinality_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xRz43tekxSk"
      },
      "outputs": [],
      "source": [
        "# 순서형\n",
        "ordinal = ['person_attribute_a_1','person_attribute_b','person_prefer_e','contents_attribute_e']\n",
        "# 명목형\n",
        "nominal = list(set(cate) - set(ordinal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1XZkbXnt4UC"
      },
      "outputs": [],
      "source": [
        "# # {'salary' : ['low', 'medium', 'high']})\n",
        "# ordinal_features = {'person_attribute_a_1':['0','1','2','3','4','5','6','7'], \n",
        "#                     'person_attribute_b':['0','1','2','3','4','5'], \n",
        "#                     'person_prefer_e':['0','1','2','3','4','5','6','7','8','9','10','11'], \n",
        "#                     'contents_attribute_e':['0','1','2','3','4','5','6','7','8','9','10','11'] }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZGqA6b7o6Sh"
      },
      "outputs": [],
      "source": [
        "# from pycaret.classification import *\n",
        "# clf = setup(data = train, target = 'target', categorical_features=cat_features,\n",
        "#             ordinal_features = ordinal_features,\n",
        "#             session_id = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#catboost\n",
        "! pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ-PTB5x4nwa",
        "outputId": "9851d484-91d7-4c01-c7fe-c8e4bedcadeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import skew\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from math import sqrt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import gc\n",
        "\n",
        "NFOLDS = 5\n",
        "SEED = 0\n",
        "NROWS = None\n",
        "\n",
        "# print('%-55s | %7s | %10s | %10s | %10s' \n",
        "#       % ('FEATURES', 'TYPE', 'NB VALUES', 'NB NaNS', 'NaNs (%)'))\n",
        "# for f_ in data: # .dtypes\n",
        "#     print(\"%-55s | %7s | %10s | %10s |    %5.2f\"\n",
        "#           % (f_, str(data[f_].dtype), \n",
        "#              str(len(data[f_].value_counts(dropna=False))), \n",
        "#              str(data[f_].isnull().sum()),\n",
        "#              100 * data[f_].isnull().sum() / data.shape[0]\n",
        "#             )\n",
        "#          )\n",
        "\n",
        "# categorical_feats = [\n",
        "#     f for f in data.columns if data[f].dtype == 'object'\n",
        "# ]\n",
        "\n",
        "# for f_ in cate:\n",
        "#     train[f_], indexer = pd.factorize(train[f_])\n",
        "#     test[f_] = indexer.get_indexer(test[f_])\n",
        "    \n",
        "gc.enable()\n",
        "\n",
        "train = job_data.drop(drop,axis=1)\n",
        "test = job_data_test.drop(drop,axis=1)\n",
        "y_train = train['target']\n",
        "del train['target']\n",
        "\n",
        "###################################\n",
        "# PLEASE DON'T DO THIS AT HOME LOL\n",
        "# Averaging factorized categorical features defeats my own reasoning\n",
        "################################### \n",
        "# prev_cat_features = [\n",
        "#     f_ for f_ in prev.columns if prev[f_].dtype == 'object'\n",
        "# ]\n",
        "# for f_ in cate:\n",
        "#     train[f_], _ = pd.factorize(train[f_])\n",
        "    \n",
        "# avg_prev = prev.groupby('SK_ID_CURR').mean()\n",
        "# cnt_prev = prev[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
        "# avg_prev['nb_app'] = cnt_prev['SK_ID_PREV']\n",
        "# del avg_prev['SK_ID_PREV']\n",
        "\n",
        "# x_train = data.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
        "# x_test = test.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
        "\n",
        "# x_train = x_train.fillna(0)\n",
        "# x_test= x_test.fillna(0)\n",
        "\n",
        "# ntrain = x_train.shape[0]\n",
        "# ntest = x_test.shape[0]\n",
        "\n",
        "# excluded_feats = ['SK_ID_CURR']\n",
        "# features = [f_ for f_ in x_train.columns if f_ not in excluded_feats]\n",
        "\n",
        "# x_train = x_train[features]\n",
        "# x_test = x_test[features]\n",
        "\n",
        "x_train = train.copy()\n",
        "x_test = test.copy()\n",
        "\n",
        "#int type category로 변경\n",
        "# for i in enumerate(cate):\n",
        "#   ca = i[1]\n",
        "#   x_train[ca] = x_train[ca].astype('category')\n",
        "#   x_test[ca] = x_test[ca].astype('category')\n",
        "\n",
        "ntrain = x_train.shape[0]\n",
        "ntest = x_test.shape[0]\n",
        "\n",
        "kf = KFold(n_splits = NFOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "class SklearnWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['random_state'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict_proba(x)[:,1]\n",
        "\n",
        "class CatboostWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['random_seed'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict_proba(x)[:,1]\n",
        "        \n",
        "class LightGBMWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['feature_fraction_seed'] = seed\n",
        "        params['bagging_seed'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict_proba(x)[:,1]\n",
        "\n",
        "\n",
        "class XgbWrapper(object):\n",
        "    def __init__(self, seed=0, params=None):\n",
        "        self.param = params\n",
        "        self.param['seed'] = seed\n",
        "        self.nrounds = params.pop('nrounds', 250)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
        "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.gbdt.predict(xgb.DMatrix(x))\n",
        "\n",
        "\n",
        "def get_oof(clf):\n",
        "    oof_train = np.zeros((ntrain,))\n",
        "    oof_test = np.zeros((ntest,))\n",
        "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
        "        x_tr = x_train.loc[train_index]\n",
        "        y_tr = y_train.loc[train_index]\n",
        "        x_te = x_train.loc[test_index]\n",
        "\n",
        "        clf.train(x_tr, y_tr)\n",
        "\n",
        "        oof_train[test_index] = clf.predict(x_te)\n",
        "        oof_test_skf[i, :] = clf.predict(x_test)\n",
        "\n",
        "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
        "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
        "\n",
        "\n",
        "et_params = {\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators': 200,\n",
        "    'max_features': 0.5,\n",
        "    'max_depth': 12,\n",
        "    'min_samples_leaf': 2,\n",
        "}\n",
        "\n",
        "rf_params = {\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators': 200,\n",
        "    'max_features': 0.2,\n",
        "    'max_depth': 12,\n",
        "    'min_samples_leaf': 2,\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    'seed': 0,\n",
        "    'colsample_bytree': 0.9689,\n",
        "    'silent': 1,\n",
        "    'subsample': 0.7281,\n",
        "    'learning_rate': 0.01936,\n",
        "    'objective': 'binary:logistic',\n",
        "    'max_depth': 3,\n",
        "    'num_parallel_tree': 1,\n",
        "    'min_child_weight': 618.567,\n",
        "    'nrounds': 500,\n",
        "    'num_leaves':14,\n",
        "    'reg_alpha':58.55,\n",
        "    'reg_lambda':0.29\n",
        "}\n",
        "\n",
        "catboost_params = {\n",
        "    'iterations': 30,\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 10,\n",
        "#    'l2_leaf_reg': 40,\n",
        "#    'bootstrap_type': 'Bernoulli',\n",
        "#    'subsample': 0.8,\n",
        "#    'scale_pos_weight': 5,\n",
        "    'eval_metric': 'F1',\n",
        "#    'od_type': 'Iter',\n",
        "    'allow_writing_files': False,\n",
        "    'cat_features' : cate #######\n",
        "}\n",
        "\n",
        "lightgbm_params = {\n",
        "#    'n_estimators':200,\n",
        "    'learning_rate':0.1,\n",
        "    'num_leaves':42,\n",
        "    'colsample_bytree':0.422,\n",
        "    'subsample':0.925,\n",
        "    'max_depth':7,\n",
        "    'reg_alpha':11.7,\n",
        "    'reg_lambda':75.1,\n",
        "#    'min_split_gain':0.01,\n",
        "    'min_child_weight':179.736    \n",
        "}\n",
        "\n",
        "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
        "et = SklearnWrapper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
        "rf = SklearnWrapper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
        "cb = CatboostWrapper(clf= CatBoostClassifier, seed = SEED, params=catboost_params)\n",
        "lg = LightGBMWrapper(clf = LGBMClassifier, seed = SEED, params = lightgbm_params)\n",
        "\n",
        "xg_oof_train, xg_oof_test = get_oof(xg)\n",
        "et_oof_train, et_oof_test = get_oof(et)\n",
        "rf_oof_train, rf_oof_test = get_oof(rf)\n",
        "cb_oof_train, cb_oof_test = get_oof(cb)\n",
        "lg_oof_train, lg_oof_test = get_oof(lg)\n",
        "\n",
        "print(\"XG-CV: {}\".format(f1_score(y_train, np.round(xg_oof_train).astype(int))))\n",
        "print(\"ET-CV: {}\".format(f1_score(y_train, np.round(et_oof_train).astype(int))))\n",
        "print(\"RF-CV: {}\".format(f1_score(y_train, np.round(rf_oof_train).astype(int))))\n",
        "print(\"CB-CV: {}\".format(f1_score(y_train, np.round(cb_oof_train).astype(int))))\n",
        "print(\"LG-CV: {}\".format(f1_score(y_train, np.round(lg_oof_train).astype(int))))\n",
        "\n",
        "x_train = np.concatenate((xg_oof_train,\n",
        "                          et_oof_train, \n",
        "                          rf_oof_train, \n",
        "                          cb_oof_train, \n",
        "                          lg_oof_train), axis=1)\n",
        "x_test = np.concatenate((xg_oof_test, \n",
        "                         et_oof_test, \n",
        "                         rf_oof_test, \n",
        "                         cb_oof_test,\n",
        "                         lg_oof_test), axis=1)\n",
        "\n",
        "print(\"{},{}\".format(x_train.shape, x_test.shape))\n",
        "\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(x_train,y_train)\n",
        "\n",
        "test['target'] = logistic_regression.predict_proba(x_test)[:,1]\n",
        "\n",
        "#test[['SK_ID_CURR', 'TARGET']].to_csv('first_submission.csv', index=False, float_format='%.8f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukpkCyOgyssU",
        "outputId": "429c95e8-9989-4d09-b31a-b7f54ef29974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6049409\ttotal: 2.15s\tremaining: 1m 2s\n",
            "1:\tlearn: 0.6021437\ttotal: 3.88s\tremaining: 54.4s\n",
            "2:\tlearn: 0.6084800\ttotal: 5.44s\tremaining: 49s\n",
            "3:\tlearn: 0.6060773\ttotal: 6.96s\tremaining: 45.3s\n",
            "4:\tlearn: 0.6130648\ttotal: 8.73s\tremaining: 43.7s\n",
            "5:\tlearn: 0.6126394\ttotal: 10.2s\tremaining: 40.9s\n",
            "6:\tlearn: 0.6133983\ttotal: 11.7s\tremaining: 38.5s\n",
            "7:\tlearn: 0.6164065\ttotal: 13.2s\tremaining: 36.4s\n",
            "8:\tlearn: 0.6158633\ttotal: 14.8s\tremaining: 34.4s\n",
            "9:\tlearn: 0.6173562\ttotal: 16.3s\tremaining: 32.5s\n",
            "10:\tlearn: 0.6184459\ttotal: 17.8s\tremaining: 30.8s\n",
            "11:\tlearn: 0.6192983\ttotal: 19.3s\tremaining: 29s\n",
            "12:\tlearn: 0.6192237\ttotal: 20.8s\tremaining: 27.2s\n",
            "13:\tlearn: 0.6192554\ttotal: 22.3s\tremaining: 25.5s\n",
            "14:\tlearn: 0.6189455\ttotal: 23.8s\tremaining: 23.8s\n",
            "15:\tlearn: 0.6191004\ttotal: 25.3s\tremaining: 22.2s\n",
            "16:\tlearn: 0.6193224\ttotal: 26.8s\tremaining: 20.5s\n",
            "17:\tlearn: 0.6191936\ttotal: 28.4s\tremaining: 18.9s\n",
            "18:\tlearn: 0.6198486\ttotal: 29.9s\tremaining: 17.3s\n",
            "19:\tlearn: 0.6203302\ttotal: 31.4s\tremaining: 15.7s\n",
            "20:\tlearn: 0.6206486\ttotal: 33s\tremaining: 14.1s\n",
            "21:\tlearn: 0.6209117\ttotal: 34.5s\tremaining: 12.5s\n",
            "22:\tlearn: 0.6220537\ttotal: 36s\tremaining: 11s\n",
            "23:\tlearn: 0.6231233\ttotal: 37.5s\tremaining: 9.39s\n",
            "24:\tlearn: 0.6232899\ttotal: 39.1s\tremaining: 7.81s\n",
            "25:\tlearn: 0.6235767\ttotal: 40.6s\tremaining: 6.24s\n",
            "26:\tlearn: 0.6238580\ttotal: 42.1s\tremaining: 4.67s\n",
            "27:\tlearn: 0.6244085\ttotal: 43.6s\tremaining: 3.11s\n",
            "28:\tlearn: 0.6250842\ttotal: 45.1s\tremaining: 1.55s\n",
            "29:\tlearn: 0.6253906\ttotal: 46.6s\tremaining: 0us\n",
            "0:\tlearn: 0.6113376\ttotal: 2.03s\tremaining: 58.8s\n",
            "1:\tlearn: 0.6197292\ttotal: 3.92s\tremaining: 54.9s\n",
            "2:\tlearn: 0.6105557\ttotal: 5.75s\tremaining: 51.8s\n",
            "3:\tlearn: 0.6107425\ttotal: 7.25s\tremaining: 47.1s\n",
            "4:\tlearn: 0.6122040\ttotal: 8.75s\tremaining: 43.8s\n",
            "5:\tlearn: 0.6106174\ttotal: 10.3s\tremaining: 41.1s\n",
            "6:\tlearn: 0.6126214\ttotal: 11.8s\tremaining: 38.7s\n",
            "7:\tlearn: 0.6133830\ttotal: 13.3s\tremaining: 36.6s\n",
            "8:\tlearn: 0.6141888\ttotal: 14.8s\tremaining: 34.6s\n",
            "9:\tlearn: 0.6144572\ttotal: 16.3s\tremaining: 32.7s\n",
            "10:\tlearn: 0.6151399\ttotal: 17.9s\tremaining: 30.8s\n",
            "11:\tlearn: 0.6145924\ttotal: 19.4s\tremaining: 29.1s\n",
            "12:\tlearn: 0.6152077\ttotal: 20.9s\tremaining: 27.3s\n",
            "13:\tlearn: 0.6156604\ttotal: 22.4s\tremaining: 25.6s\n",
            "14:\tlearn: 0.6152164\ttotal: 23.9s\tremaining: 23.9s\n",
            "15:\tlearn: 0.6162027\ttotal: 25.4s\tremaining: 22.2s\n",
            "16:\tlearn: 0.6164291\ttotal: 26.9s\tremaining: 20.6s\n",
            "17:\tlearn: 0.6166548\ttotal: 28.4s\tremaining: 18.9s\n",
            "18:\tlearn: 0.6173256\ttotal: 29.9s\tremaining: 17.3s\n",
            "19:\tlearn: 0.6182442\ttotal: 31.4s\tremaining: 15.7s\n",
            "20:\tlearn: 0.6195098\ttotal: 33s\tremaining: 14.1s\n",
            "21:\tlearn: 0.6197434\ttotal: 34.5s\tremaining: 12.5s\n",
            "22:\tlearn: 0.6204096\ttotal: 36s\tremaining: 11s\n",
            "23:\tlearn: 0.6208859\ttotal: 37.5s\tremaining: 9.38s\n",
            "24:\tlearn: 0.6217808\ttotal: 39.1s\tremaining: 7.81s\n",
            "25:\tlearn: 0.6218946\ttotal: 40.6s\tremaining: 6.24s\n",
            "26:\tlearn: 0.6221713\ttotal: 42.1s\tremaining: 4.67s\n",
            "27:\tlearn: 0.6227839\ttotal: 43.6s\tremaining: 3.11s\n",
            "28:\tlearn: 0.6232954\ttotal: 45.2s\tremaining: 1.56s\n",
            "29:\tlearn: 0.6240277\ttotal: 46.7s\tremaining: 0us\n",
            "0:\tlearn: 0.6108482\ttotal: 1.87s\tremaining: 54.4s\n",
            "1:\tlearn: 0.6114429\ttotal: 3.67s\tremaining: 51.4s\n",
            "2:\tlearn: 0.6082323\ttotal: 5.37s\tremaining: 48.4s\n",
            "3:\tlearn: 0.6142673\ttotal: 6.92s\tremaining: 45s\n",
            "4:\tlearn: 0.6224649\ttotal: 8.44s\tremaining: 42.2s\n",
            "5:\tlearn: 0.6225683\ttotal: 9.95s\tremaining: 39.8s\n",
            "6:\tlearn: 0.6238608\ttotal: 11.5s\tremaining: 37.7s\n",
            "7:\tlearn: 0.6195483\ttotal: 13s\tremaining: 35.7s\n",
            "8:\tlearn: 0.6168257\ttotal: 14.5s\tremaining: 33.9s\n",
            "9:\tlearn: 0.6163206\ttotal: 16s\tremaining: 32.1s\n",
            "10:\tlearn: 0.6156885\ttotal: 17.6s\tremaining: 30.4s\n",
            "11:\tlearn: 0.6164399\ttotal: 18.3s\tremaining: 27.5s\n",
            "12:\tlearn: 0.6160462\ttotal: 19.9s\tremaining: 26s\n",
            "13:\tlearn: 0.6155202\ttotal: 21.4s\tremaining: 24.4s\n",
            "14:\tlearn: 0.6163007\ttotal: 22.9s\tremaining: 22.9s\n",
            "15:\tlearn: 0.6172946\ttotal: 24.4s\tremaining: 21.4s\n",
            "16:\tlearn: 0.6173331\ttotal: 25.9s\tremaining: 19.8s\n",
            "17:\tlearn: 0.6188504\ttotal: 27.5s\tremaining: 18.3s\n",
            "18:\tlearn: 0.6199349\ttotal: 29s\tremaining: 16.8s\n",
            "19:\tlearn: 0.6211496\ttotal: 30.5s\tremaining: 15.2s\n",
            "20:\tlearn: 0.6216285\ttotal: 32s\tremaining: 13.7s\n",
            "21:\tlearn: 0.6215572\ttotal: 33.5s\tremaining: 12.2s\n",
            "22:\tlearn: 0.6221459\ttotal: 35s\tremaining: 10.7s\n",
            "23:\tlearn: 0.6221723\ttotal: 36.5s\tremaining: 9.14s\n",
            "24:\tlearn: 0.6226595\ttotal: 38.1s\tremaining: 7.62s\n",
            "25:\tlearn: 0.6229740\ttotal: 39.6s\tremaining: 6.09s\n",
            "26:\tlearn: 0.6227475\ttotal: 41.1s\tremaining: 4.57s\n",
            "27:\tlearn: 0.6234295\ttotal: 42.6s\tremaining: 3.04s\n",
            "28:\tlearn: 0.6236055\ttotal: 44.1s\tremaining: 1.52s\n",
            "29:\tlearn: 0.6242247\ttotal: 45.7s\tremaining: 0us\n",
            "0:\tlearn: 0.6029496\ttotal: 1.9s\tremaining: 55.1s\n",
            "1:\tlearn: 0.6209392\ttotal: 3.69s\tremaining: 51.7s\n",
            "2:\tlearn: 0.6219598\ttotal: 5.41s\tremaining: 48.7s\n",
            "3:\tlearn: 0.6227074\ttotal: 6.94s\tremaining: 45.1s\n",
            "4:\tlearn: 0.6175121\ttotal: 8.46s\tremaining: 42.3s\n",
            "5:\tlearn: 0.6117093\ttotal: 9.98s\tremaining: 39.9s\n",
            "6:\tlearn: 0.6105272\ttotal: 11.5s\tremaining: 37.8s\n",
            "7:\tlearn: 0.6105378\ttotal: 13s\tremaining: 35.8s\n",
            "8:\tlearn: 0.6115442\ttotal: 14.5s\tremaining: 33.9s\n",
            "9:\tlearn: 0.6125406\ttotal: 16s\tremaining: 32s\n",
            "10:\tlearn: 0.6120592\ttotal: 17.6s\tremaining: 30.3s\n",
            "11:\tlearn: 0.6123414\ttotal: 19.1s\tremaining: 28.6s\n",
            "12:\tlearn: 0.6127653\ttotal: 20.6s\tremaining: 27s\n",
            "13:\tlearn: 0.6139393\ttotal: 22.1s\tremaining: 25.3s\n",
            "14:\tlearn: 0.6151014\ttotal: 23.7s\tremaining: 23.7s\n",
            "15:\tlearn: 0.6160195\ttotal: 25.2s\tremaining: 22s\n",
            "16:\tlearn: 0.6164211\ttotal: 26.7s\tremaining: 20.4s\n",
            "17:\tlearn: 0.6169462\ttotal: 28.2s\tremaining: 18.8s\n",
            "18:\tlearn: 0.6171839\ttotal: 29.7s\tremaining: 17.2s\n",
            "19:\tlearn: 0.6175091\ttotal: 31.2s\tremaining: 15.6s\n",
            "20:\tlearn: 0.6181237\ttotal: 32.8s\tremaining: 14s\n",
            "21:\tlearn: 0.6188233\ttotal: 34.3s\tremaining: 12.5s\n",
            "22:\tlearn: 0.6195962\ttotal: 35.9s\tremaining: 10.9s\n",
            "23:\tlearn: 0.6201673\ttotal: 37.4s\tremaining: 9.35s\n",
            "24:\tlearn: 0.6209597\ttotal: 38.9s\tremaining: 7.77s\n",
            "25:\tlearn: 0.6217173\ttotal: 40.4s\tremaining: 6.22s\n",
            "26:\tlearn: 0.6219300\ttotal: 42s\tremaining: 4.66s\n",
            "27:\tlearn: 0.6219826\ttotal: 43.5s\tremaining: 3.1s\n",
            "28:\tlearn: 0.6227258\ttotal: 45s\tremaining: 1.55s\n",
            "29:\tlearn: 0.6228036\ttotal: 46.5s\tremaining: 0us\n",
            "0:\tlearn: 0.6286275\ttotal: 1.81s\tremaining: 52.4s\n",
            "1:\tlearn: 0.6275383\ttotal: 3.52s\tremaining: 49.3s\n",
            "2:\tlearn: 0.6235433\ttotal: 5.24s\tremaining: 47.1s\n",
            "3:\tlearn: 0.6195206\ttotal: 6.75s\tremaining: 43.9s\n",
            "4:\tlearn: 0.6149261\ttotal: 8.3s\tremaining: 41.5s\n",
            "5:\tlearn: 0.6166296\ttotal: 9.81s\tremaining: 39.2s\n",
            "6:\tlearn: 0.6169207\ttotal: 11.4s\tremaining: 37.3s\n",
            "7:\tlearn: 0.6174156\ttotal: 12.9s\tremaining: 35.4s\n",
            "8:\tlearn: 0.6180482\ttotal: 14.4s\tremaining: 33.6s\n",
            "9:\tlearn: 0.6200156\ttotal: 15.9s\tremaining: 31.8s\n",
            "10:\tlearn: 0.6197703\ttotal: 17.4s\tremaining: 30.1s\n",
            "11:\tlearn: 0.6196686\ttotal: 18.9s\tremaining: 28.4s\n",
            "12:\tlearn: 0.6195617\ttotal: 20.4s\tremaining: 26.7s\n",
            "13:\tlearn: 0.6197007\ttotal: 21.9s\tremaining: 25.1s\n",
            "14:\tlearn: 0.6197641\ttotal: 23.4s\tremaining: 23.4s\n",
            "15:\tlearn: 0.6201841\ttotal: 24.9s\tremaining: 21.8s\n",
            "16:\tlearn: 0.6211505\ttotal: 26.4s\tremaining: 20.2s\n",
            "17:\tlearn: 0.6221429\ttotal: 28s\tremaining: 18.6s\n",
            "18:\tlearn: 0.6221350\ttotal: 29.5s\tremaining: 17.1s\n",
            "19:\tlearn: 0.6224971\ttotal: 31s\tremaining: 15.5s\n",
            "20:\tlearn: 0.6231660\ttotal: 32.5s\tremaining: 13.9s\n",
            "21:\tlearn: 0.6231587\ttotal: 34s\tremaining: 12.4s\n",
            "22:\tlearn: 0.6239377\ttotal: 35.5s\tremaining: 10.8s\n",
            "23:\tlearn: 0.6239244\ttotal: 37s\tremaining: 9.26s\n",
            "24:\tlearn: 0.6240937\ttotal: 38.5s\tremaining: 7.71s\n",
            "25:\tlearn: 0.6241259\ttotal: 40s\tremaining: 6.16s\n",
            "26:\tlearn: 0.6247836\ttotal: 41.5s\tremaining: 4.62s\n",
            "27:\tlearn: 0.6252547\ttotal: 43s\tremaining: 3.07s\n",
            "28:\tlearn: 0.6250711\ttotal: 44.5s\tremaining: 1.54s\n",
            "29:\tlearn: 0.6249385\ttotal: 46.1s\tremaining: 0us\n",
            "XG-CV: 0.6137717582199856\n",
            "ET-CV: 0.6228011941929145\n",
            "RF-CV: 0.6304143699735923\n",
            "CB-CV: 0.6211326305467025\n",
            "LG-CV: 0.6314549351656203\n",
            "(501951, 5),(46404, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = logistic_regression.predict(x_test)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQBb9AaQWITA",
        "outputId": "7f1b6253-cfe8-4fdd-f470-b87656872641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission['target'] = pred\n",
        "submission.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EGk7cwKeXggr",
        "outputId": "936ed1d5-6d6f-49bc-eec7-5f4e41f5e0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fe836e3d-bb36-4730-8477-026afb075e3a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe836e3d-bb36-4730-8477-026afb075e3a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe836e3d-bb36-4730-8477-026afb075e3a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe836e3d-bb36-4730-8477-026afb075e3a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  target\n",
              "0   0       0\n",
              "1   1       0\n",
              "2   2       0\n",
              "3   3       0\n",
              "4   4       0"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"lgb+xgb+cat+rf+et_stacking.csv\",index=False)"
      ],
      "metadata": {
        "id": "A6nDWWJcXyWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "MPRjFGVEJ5-z",
        "outputId": "cb5b5bd0-24ca-42e2-ac79-37803672c649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-faff7f81-6fec-4ccd-9ffa-f436f312b218\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d_l_match_yn</th>\n",
              "      <th>d_m_match_yn</th>\n",
              "      <th>d_s_match_yn</th>\n",
              "      <th>h_l_match_yn</th>\n",
              "      <th>h_m_match_yn</th>\n",
              "      <th>h_s_match_yn</th>\n",
              "      <th>person_attribute_a</th>\n",
              "      <th>person_attribute_a_1</th>\n",
              "      <th>person_attribute_b</th>\n",
              "      <th>person_prefer_c</th>\n",
              "      <th>person_prefer_d_1</th>\n",
              "      <th>person_prefer_d_2</th>\n",
              "      <th>person_prefer_d_3</th>\n",
              "      <th>person_prefer_e</th>\n",
              "      <th>person_prefer_h_1</th>\n",
              "      <th>person_prefer_h_2</th>\n",
              "      <th>person_prefer_h_3</th>\n",
              "      <th>contents_attribute_i</th>\n",
              "      <th>contents_attribute_a</th>\n",
              "      <th>contents_attribute_j_1</th>\n",
              "      <th>contents_attribute_j</th>\n",
              "      <th>contents_attribute_c</th>\n",
              "      <th>contents_attribute_k</th>\n",
              "      <th>contents_attribute_l</th>\n",
              "      <th>contents_attribute_d</th>\n",
              "      <th>contents_attribute_m</th>\n",
              "      <th>contents_attribute_e</th>\n",
              "      <th>contents_attribute_h</th>\n",
              "      <th>person_prefer_d_1_n</th>\n",
              "      <th>person_prefer_d_1_s</th>\n",
              "      <th>person_prefer_d_1_m</th>\n",
              "      <th>person_prefer_d_1_l</th>\n",
              "      <th>person_prefer_d_2_n</th>\n",
              "      <th>person_prefer_d_2_s</th>\n",
              "      <th>person_prefer_d_2_m</th>\n",
              "      <th>person_prefer_d_2_l</th>\n",
              "      <th>person_prefer_d_3_n</th>\n",
              "      <th>person_prefer_d_3_s</th>\n",
              "      <th>person_prefer_d_3_m</th>\n",
              "      <th>person_prefer_d_3_l</th>\n",
              "      <th>contents_attribute_d_n</th>\n",
              "      <th>contents_attribute_d_s</th>\n",
              "      <th>contents_attribute_d_m</th>\n",
              "      <th>contents_attribute_d_l</th>\n",
              "      <th>person_prefer_h_1_l</th>\n",
              "      <th>person_prefer_h_1_m</th>\n",
              "      <th>person_prefer_h_2_l</th>\n",
              "      <th>person_prefer_h_2_m</th>\n",
              "      <th>person_prefer_h_3_l</th>\n",
              "      <th>person_prefer_h_3_m</th>\n",
              "      <th>contents_attribute_h_l</th>\n",
              "      <th>contents_attribute_h_m</th>\n",
              "      <th>contents_attribute_l_n</th>\n",
              "      <th>contents_attribute_l_s</th>\n",
              "      <th>contents_attribute_l_m</th>\n",
              "      <th>contents_attribute_l_l</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>857</td>\n",
              "      <td>851</td>\n",
              "      <td>1227</td>\n",
              "      <td>4</td>\n",
              "      <td>263</td>\n",
              "      <td>56</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1147</td>\n",
              "      <td>839</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>263</td>\n",
              "      <td>854</td>\n",
              "      <td>853</td>\n",
              "      <td>824</td>\n",
              "      <td>744</td>\n",
              "      <td>847</td>\n",
              "      <td>847</td>\n",
              "      <td>824</td>\n",
              "      <td>744</td>\n",
              "      <td>1227</td>\n",
              "      <td>1227</td>\n",
              "      <td>1227</td>\n",
              "      <td>926</td>\n",
              "      <td>836</td>\n",
              "      <td>831</td>\n",
              "      <td>824</td>\n",
              "      <td>744</td>\n",
              "      <td>250</td>\n",
              "      <td>528</td>\n",
              "      <td>48</td>\n",
              "      <td>366</td>\n",
              "      <td>48</td>\n",
              "      <td>359</td>\n",
              "      <td>250</td>\n",
              "      <td>528</td>\n",
              "      <td>1146</td>\n",
              "      <td>1128</td>\n",
              "      <td>1021</td>\n",
              "      <td>2010</td>\n",
              "      <td>0.489707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>683</td>\n",
              "      <td>1086</td>\n",
              "      <td>662</td>\n",
              "      <td>2</td>\n",
              "      <td>258</td>\n",
              "      <td>263</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1611</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>263</td>\n",
              "      <td>683</td>\n",
              "      <td>677</td>\n",
              "      <td>659</td>\n",
              "      <td>618</td>\n",
              "      <td>1086</td>\n",
              "      <td>1086</td>\n",
              "      <td>1053</td>\n",
              "      <td>926</td>\n",
              "      <td>662</td>\n",
              "      <td>660</td>\n",
              "      <td>659</td>\n",
              "      <td>618</td>\n",
              "      <td>276</td>\n",
              "      <td>274</td>\n",
              "      <td>274</td>\n",
              "      <td>216</td>\n",
              "      <td>250</td>\n",
              "      <td>523</td>\n",
              "      <td>250</td>\n",
              "      <td>528</td>\n",
              "      <td>48</td>\n",
              "      <td>359</td>\n",
              "      <td>250</td>\n",
              "      <td>528</td>\n",
              "      <td>1610</td>\n",
              "      <td>1606</td>\n",
              "      <td>1605</td>\n",
              "      <td>2016</td>\n",
              "      <td>0.426063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>514</td>\n",
              "      <td>790</td>\n",
              "      <td>1233</td>\n",
              "      <td>0</td>\n",
              "      <td>177</td>\n",
              "      <td>170</td>\n",
              "      <td>171</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1817</td>\n",
              "      <td>490</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>177</td>\n",
              "      <td>514</td>\n",
              "      <td>509</td>\n",
              "      <td>482</td>\n",
              "      <td>482</td>\n",
              "      <td>784</td>\n",
              "      <td>783</td>\n",
              "      <td>745</td>\n",
              "      <td>744</td>\n",
              "      <td>1227</td>\n",
              "      <td>1227</td>\n",
              "      <td>1227</td>\n",
              "      <td>926</td>\n",
              "      <td>490</td>\n",
              "      <td>490</td>\n",
              "      <td>482</td>\n",
              "      <td>482</td>\n",
              "      <td>169</td>\n",
              "      <td>453</td>\n",
              "      <td>169</td>\n",
              "      <td>451</td>\n",
              "      <td>169</td>\n",
              "      <td>452</td>\n",
              "      <td>169</td>\n",
              "      <td>453</td>\n",
              "      <td>1812</td>\n",
              "      <td>1811</td>\n",
              "      <td>1810</td>\n",
              "      <td>2020</td>\n",
              "      <td>0.451051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>114</td>\n",
              "      <td>181</td>\n",
              "      <td>175</td>\n",
              "      <td>4</td>\n",
              "      <td>177</td>\n",
              "      <td>170</td>\n",
              "      <td>171</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>101</td>\n",
              "      <td>150</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>177</td>\n",
              "      <td>114</td>\n",
              "      <td>109</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>175</td>\n",
              "      <td>152</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>175</td>\n",
              "      <td>152</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>169</td>\n",
              "      <td>453</td>\n",
              "      <td>169</td>\n",
              "      <td>451</td>\n",
              "      <td>169</td>\n",
              "      <td>452</td>\n",
              "      <td>169</td>\n",
              "      <td>453</td>\n",
              "      <td>101</td>\n",
              "      <td>100</td>\n",
              "      <td>99</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.486292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1082</td>\n",
              "      <td>1078</td>\n",
              "      <td>1056</td>\n",
              "      <td>5</td>\n",
              "      <td>178</td>\n",
              "      <td>177</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>985</td>\n",
              "      <td>1097</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>177</td>\n",
              "      <td>1078</td>\n",
              "      <td>1078</td>\n",
              "      <td>1053</td>\n",
              "      <td>926</td>\n",
              "      <td>1078</td>\n",
              "      <td>1078</td>\n",
              "      <td>1053</td>\n",
              "      <td>926</td>\n",
              "      <td>1056</td>\n",
              "      <td>1054</td>\n",
              "      <td>1053</td>\n",
              "      <td>926</td>\n",
              "      <td>1097</td>\n",
              "      <td>1094</td>\n",
              "      <td>1093</td>\n",
              "      <td>926</td>\n",
              "      <td>169</td>\n",
              "      <td>454</td>\n",
              "      <td>169</td>\n",
              "      <td>453</td>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>169</td>\n",
              "      <td>453</td>\n",
              "      <td>984</td>\n",
              "      <td>980</td>\n",
              "      <td>954</td>\n",
              "      <td>2009</td>\n",
              "      <td>0.477890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46399</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>147</td>\n",
              "      <td>46</td>\n",
              "      <td>145</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>95</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>759</td>\n",
              "      <td>147</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>91</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>315</td>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>94</td>\n",
              "      <td>398</td>\n",
              "      <td>85</td>\n",
              "      <td>396</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.681178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46400</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>176</td>\n",
              "      <td>120</td>\n",
              "      <td>159</td>\n",
              "      <td>4</td>\n",
              "      <td>86</td>\n",
              "      <td>31</td>\n",
              "      <td>278</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>759</td>\n",
              "      <td>147</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>91</td>\n",
              "      <td>175</td>\n",
              "      <td>152</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>114</td>\n",
              "      <td>109</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>159</td>\n",
              "      <td>152</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>391</td>\n",
              "      <td>30</td>\n",
              "      <td>342</td>\n",
              "      <td>277</td>\n",
              "      <td>542</td>\n",
              "      <td>85</td>\n",
              "      <td>396</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.502354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46401</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>46</td>\n",
              "      <td>147</td>\n",
              "      <td>5</td>\n",
              "      <td>288</td>\n",
              "      <td>279</td>\n",
              "      <td>278</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>759</td>\n",
              "      <td>147</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>288</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>277</td>\n",
              "      <td>547</td>\n",
              "      <td>277</td>\n",
              "      <td>543</td>\n",
              "      <td>277</td>\n",
              "      <td>542</td>\n",
              "      <td>277</td>\n",
              "      <td>547</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.640289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46402</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>145</td>\n",
              "      <td>46</td>\n",
              "      <td>147</td>\n",
              "      <td>6</td>\n",
              "      <td>288</td>\n",
              "      <td>279</td>\n",
              "      <td>278</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>759</td>\n",
              "      <td>147</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>288</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>277</td>\n",
              "      <td>547</td>\n",
              "      <td>277</td>\n",
              "      <td>543</td>\n",
              "      <td>277</td>\n",
              "      <td>542</td>\n",
              "      <td>277</td>\n",
              "      <td>547</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.667035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46403</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>46</td>\n",
              "      <td>147</td>\n",
              "      <td>0</td>\n",
              "      <td>288</td>\n",
              "      <td>280</td>\n",
              "      <td>283</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>759</td>\n",
              "      <td>147</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>288</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>277</td>\n",
              "      <td>547</td>\n",
              "      <td>277</td>\n",
              "      <td>543</td>\n",
              "      <td>277</td>\n",
              "      <td>543</td>\n",
              "      <td>277</td>\n",
              "      <td>547</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>759</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.631276</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46404 rows × 57 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faff7f81-6fec-4ccd-9ffa-f436f312b218')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-faff7f81-6fec-4ccd-9ffa-f436f312b218 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-faff7f81-6fec-4ccd-9ffa-f436f312b218');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       d_l_match_yn  d_m_match_yn  ...  contents_attribute_l_l    target\n",
              "0              True         False  ...                    2010  0.489707\n",
              "1             False         False  ...                    2016  0.426063\n",
              "2              True         False  ...                    2020  0.451051\n",
              "3              True         False  ...                    2006  0.486292\n",
              "4              True         False  ...                    2009  0.477890\n",
              "...             ...           ...  ...                     ...       ...\n",
              "46399          True          True  ...                    2006  0.681178\n",
              "46400          True         False  ...                    2006  0.502354\n",
              "46401          True          True  ...                    2006  0.640289\n",
              "46402          True          True  ...                    2006  0.667035\n",
              "46403          True          True  ...                    2006  0.631276\n",
              "\n",
              "[46404 rows x 57 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.round(test['target']).astype(int)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBUvCkgZV4Qu",
        "outputId": "8e8e83e0-dc5b-409a-9f7f-a4bf9a1998d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "46399    1\n",
              "46400    1\n",
              "46401    1\n",
              "46402    1\n",
              "46403    1\n",
              "Name: target, Length: 46404, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ntrain = x_train.shape[0]\n",
        "ntrain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePyP5fEC5N1n",
        "outputId": "777ccf5f-2963-4c2e-de3a-ef80f7c5bbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "501951"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsWX2ELgphKg"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiLpSPAMphKg"
      },
      "outputs": [],
      "source": [
        "X = train.copy()\n",
        "X = X.drop(['target'],axis=1)\n",
        "target = train['target']\n",
        "\n",
        "#int type category로 변경\n",
        "# for i in enumerate(cate):\n",
        "#     ca = i[1]\n",
        "#     X[ca] = X[ca].astype('category')\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,target,\n",
        "                                                 test_size=0.2,random_state=42, stratify = target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train.info()"
      ],
      "metadata": {
        "id": "id6KO0HHQVxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTbT4EmmphKh"
      },
      "outputs": [],
      "source": [
        "def learning_rate_010_decay_power_099(current_iter):\n",
        "  base_learning_rate = 0.1\n",
        "  lr = base_learning_rate  * np.power(.99, current_iter)\n",
        "  return lr if lr > 1e-3 else 1e-3\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "# fit_params={'early_stopping_rounds':30, \n",
        "#             'metric' : 'custom', \n",
        "#             \"eval_set\" : [(X_test,y_test)],\n",
        "#             'eval_names': ['valid'],\n",
        "#             'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
        "#             'verbose': 100,\n",
        "#             'categorical_feature': 'auto'}\n",
        "\n",
        "#set up hyperparameter search\n",
        "# from scipy.stats import randint as sp_randint\n",
        "# from scipy.stats import uniform as sp_uniform\n",
        "# param_test ={'num_leaves': list(range(6,50,3)),\n",
        "#              'min_child_samples': list(range(100,500,15)), \n",
        "#              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
        "#              'subsample': [0.2,0.4,0.6,0.8,0.9], \n",
        "#              'colsample_bytree': [0.6,0.7,0.8,0.9], \n",
        "#              'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
        "#              'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bayesian-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orBDQEwXVhEF",
        "outputId": "e23f3461-aa71-4549-ebc3-f4ea2cdf8734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.0.0)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=5f8ec5f77f5c241484b7c7e8369ffd4cc55e69ac0000c7f2739792df55e50537\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lgbm / metric = f1-score \n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import f1_score\n",
        "from bayes_opt import BayesianOptimization\n",
        "n_folds=5\n",
        "d_train = lgb.Dataset(X_train, label=y_train, free_raw_data=False) #categorical feature 수정해볼것 - contents_rn 포함, categorical data 제외\n",
        "\n",
        "# def lgb_accuracy(y_hat, data):\n",
        "#     y_true = data.get_label().astype(int)\n",
        "#     y_hat = np.around(y_hat).astype(int) # pred반올림\n",
        "#     return 'accuracy', accuracy_score(y_true, y_hat), True\n",
        "param_test ={'num_leaves': (6,45),\n",
        "             'min_child_weight': (1e-3, 1e3), #0.001 ~ 1000\n",
        "             'subsample': (0.5,1), \n",
        "             'colsample_bytree': (0.2,1), \n",
        "             'reg_alpha': (0, 100),\n",
        "             'reg_lambda': (0, 100),\n",
        "             'learning_rate': (0.01,0.2),\n",
        "             'max_depth': (3,8)}\n",
        "\n",
        "             \n",
        "# fit_params={'early_stopping_rounds':30, \n",
        "#             'metric' : 'custom', \n",
        "#             \"eval_set\" : [(X_test,y_test)],\n",
        "#             'eval_names': ['valid'],\n",
        "#             'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
        "#             'verbose': 100,\n",
        "#             'categorical_feature': 'auto'\n",
        "#             'max_depth :(3,7)'}\n",
        "\n",
        "# def accuracy(y_pred, data):\n",
        "#     y_true = np.array(data.get_label().astype(int))\n",
        "#     y_pred = (y_pred >= 0.5)\n",
        "#     score = accuracy_score(y_true, y_pred)\n",
        "\n",
        "#     return 'accuracy', score, True\n",
        "\n",
        "def lgb_f1_score(y_hat, data):\n",
        "    y_true = data.get_label().astype(int)\n",
        "#    y_hat = (y_hat >= 0.5)\n",
        "    y_hat = np.round(y_hat).astype(int) # scikits f1 doesn't like probabilities\n",
        "    return 'f1', f1_score(y_true, y_hat), True\n",
        "\n",
        "\n",
        "# def learning_rate_010_decay_power_099(current_iter):\n",
        "#   base_learning_rate = 0.1\n",
        "#   lr = base_learning_rate  * np.power(.99, current_iter)\n",
        "#   return lr if lr > 1e-3 else 1e-3    \n",
        "\n",
        "def lgb_cv(num_leaves,min_child_weight,subsample,colsample_bytree,reg_alpha,reg_lambda,max_depth,learning_rate):\n",
        "    params = {'num_iterations' : 5000, \n",
        "             'early_stopping_rounds':30, #30에서 변경\n",
        "             'n_jobs':-1,\n",
        "              'metric' : 'custom', #metric 수정\n",
        "             }\n",
        "    params['num_leaves'] = int(round(num_leaves))\n",
        "    params['min_child_weight'] = min_child_weight\n",
        "    params['subsample'] = subsample\n",
        "    params['colsample_bytree'] = colsample_bytree\n",
        "    params['reg_alpha'] = reg_alpha\n",
        "    params['reg_lambda'] = reg_lambda\n",
        "    params['learning_rate'] = learning_rate\n",
        "    params['max_depth']= int(round(max_depth))\n",
        "    lgbcv = lgb.cv(params, d_train, nfold=n_folds, seed=42, stratified=True, verbose_eval = 200,\n",
        "                   metrics=['None'], feval=lgb_f1_score)\n",
        "    \n",
        "    return max(lgbcv['f1-mean'])\n",
        "\n",
        "    \n",
        "lgbBO = BayesianOptimization(lgb_cv,param_test,random_state=42,verbose=2)\n",
        "init_round=5\n",
        "opt_round = 10\n",
        "lgbBO.maximize(init_points=init_round, n_iter=opt_round) # n_iter 찾아보기?\n",
        "print(lgbBO.max)\n",
        "# params = lgbBO.res['max']['max_params']\n",
        "# lgb2 = lgb.train(params, X_train , 100)\n",
        "# lgb2 = lgb.train(params, d_train, 100)\n",
        "# lgb_prob = lgb2.predict( y_test.values )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "9VWQE83cCXnw",
        "outputId": "ed4acfe3-4d6d-4026-ef15-e8d7caa2e102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:430: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:435: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 0.4996  \u001b[0m | \u001b[0m 0.1906  \u001b[0m | \u001b[0m 6.66    \u001b[0m | \u001b[0m 598.7   \u001b[0m | \u001b[0m 12.08   \u001b[0m | \u001b[0m 15.6    \u001b[0m | \u001b[0m 5.808   \u001b[0m | \u001b[0m 0.9331  \u001b[0m |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:430: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:435: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: (0.6808920093945671, 0.14453378978124864, 3.1029224714790122, 969.9098822521422, 38.46526299121645, 21.233911067827616, 18.182496720710063, 0.5917022549267169)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-4cb90ba2243c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0minit_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mopt_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mlgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_round\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# n_iter 찾아보기?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# params = lgbBO.res['max']['max_params']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-4cb90ba2243c>\u001b[0m in \u001b[0;36mlgb_cv\u001b[0;34m(num_leaves, min_child_weight, subsample, colsample_bytree, reg_alpha, reg_lambda, max_depth, learning_rate)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     lgbcv = lgb.cv(params, d_train, nfold=n_folds, seed=42, stratified=True, verbose_eval = 200,\n\u001b[0;32m---> 66\u001b[0;31m                    metrics=['None'], feval=lgb_f1_score)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    456\u001b[0m     cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n\u001b[1;32m    457\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                             stratified=stratified, shuffle=shuffle)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;31m# setup callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mtparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mcvbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mcvbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvbooster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1552\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m                 ctypes.byref(self.handle)))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m                         ctypes.byref(self.handle)))\n\u001b[1;32m    989\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5663\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5664\u001b[0m         \"\"\"\n\u001b[0;32m-> 5665\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5667\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lgbBO.res['max']['max_params']\n",
        "#lgbBO\n",
        "#params = {'colsample_bytree': 0.71, 'learning_rate': 0.095, 'max_depth': 6, 'min_child_weight': 703.52, 'num_leaves': 39, 'reg_alpha': 64.05, 'reg_lambda': 73.95, 'subsample': 0.74}\n",
        "#params = {'colsample_bytree': 0.24, 'min_child_weight': 866, 'num_leaves': 29, 'reg_alpha': 35.40, 'reg_lambda': 1.0, 'subsample': 0.94}\n",
        "lgb_params = {'colsample_bytree': 0.422, 'learning_rate': 0.1048, 'max_depth': 7, 'min_child_weight': 179.736, 'num_leaves': 42, 'reg_alpha': 11.704, 'reg_lambda': 75.106, 'subsample': 0.925}"
      ],
      "metadata": {
        "id": "-oAt6mCPDpkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = {'num_iterations' : 5000, 'early_stopping_rounds':100, 'n_jobs':-1, 'metric' : 'custom', 'verbose': 100, 'seed' : 42} #원래 있던 파라미터들 추가, early_stopping만 100으로 변경\n",
        "lgb_params.update(a)\n",
        "lgb2 = lgb.train(lgb_params, d_train, valid_sets= lgb.Dataset(X_test,y_test), feval=lgb_f1_score)\n",
        "\n",
        "#lgb_prob = lgb2.predict( X_test )"
      ],
      "metadata": {
        "id": "thr2B-JRIg0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01f8542-2420-49f6-f0fc-7a9b54ab2159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's f1: 0.571561\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[2]\tvalid_0's f1: 0.616071\n",
            "[3]\tvalid_0's f1: 0.615473\n",
            "[4]\tvalid_0's f1: 0.610438\n",
            "[5]\tvalid_0's f1: 0.603898\n",
            "[6]\tvalid_0's f1: 0.605951\n",
            "[7]\tvalid_0's f1: 0.599532\n",
            "[8]\tvalid_0's f1: 0.609857\n",
            "[9]\tvalid_0's f1: 0.610256\n",
            "[10]\tvalid_0's f1: 0.612791\n",
            "[11]\tvalid_0's f1: 0.61609\n",
            "[12]\tvalid_0's f1: 0.615517\n",
            "[13]\tvalid_0's f1: 0.61666\n",
            "[14]\tvalid_0's f1: 0.617322\n",
            "[15]\tvalid_0's f1: 0.618314\n",
            "[16]\tvalid_0's f1: 0.618931\n",
            "[17]\tvalid_0's f1: 0.617654\n",
            "[18]\tvalid_0's f1: 0.617614\n",
            "[19]\tvalid_0's f1: 0.619387\n",
            "[20]\tvalid_0's f1: 0.619114\n",
            "[21]\tvalid_0's f1: 0.619787\n",
            "[22]\tvalid_0's f1: 0.619757\n",
            "[23]\tvalid_0's f1: 0.619947\n",
            "[24]\tvalid_0's f1: 0.620223\n",
            "[25]\tvalid_0's f1: 0.62063\n",
            "[26]\tvalid_0's f1: 0.621051\n",
            "[27]\tvalid_0's f1: 0.621965\n",
            "[28]\tvalid_0's f1: 0.621336\n",
            "[29]\tvalid_0's f1: 0.621678\n",
            "[30]\tvalid_0's f1: 0.621763\n",
            "[31]\tvalid_0's f1: 0.622342\n",
            "[32]\tvalid_0's f1: 0.622611\n",
            "[33]\tvalid_0's f1: 0.623039\n",
            "[34]\tvalid_0's f1: 0.623456\n",
            "[35]\tvalid_0's f1: 0.623559\n",
            "[36]\tvalid_0's f1: 0.623645\n",
            "[37]\tvalid_0's f1: 0.62397\n",
            "[38]\tvalid_0's f1: 0.624079\n",
            "[39]\tvalid_0's f1: 0.624466\n",
            "[40]\tvalid_0's f1: 0.624203\n",
            "[41]\tvalid_0's f1: 0.62495\n",
            "[42]\tvalid_0's f1: 0.624714\n",
            "[43]\tvalid_0's f1: 0.624841\n",
            "[44]\tvalid_0's f1: 0.625415\n",
            "[45]\tvalid_0's f1: 0.625803\n",
            "[46]\tvalid_0's f1: 0.626108\n",
            "[47]\tvalid_0's f1: 0.626415\n",
            "[48]\tvalid_0's f1: 0.626304\n",
            "[49]\tvalid_0's f1: 0.626883\n",
            "[50]\tvalid_0's f1: 0.626772\n",
            "[51]\tvalid_0's f1: 0.62724\n",
            "[52]\tvalid_0's f1: 0.627484\n",
            "[53]\tvalid_0's f1: 0.627363\n",
            "[54]\tvalid_0's f1: 0.627289\n",
            "[55]\tvalid_0's f1: 0.627569\n",
            "[56]\tvalid_0's f1: 0.628369\n",
            "[57]\tvalid_0's f1: 0.628376\n",
            "[58]\tvalid_0's f1: 0.628728\n",
            "[59]\tvalid_0's f1: 0.629082\n",
            "[60]\tvalid_0's f1: 0.629131\n",
            "[61]\tvalid_0's f1: 0.629759\n",
            "[62]\tvalid_0's f1: 0.62966\n",
            "[63]\tvalid_0's f1: 0.629809\n",
            "[64]\tvalid_0's f1: 0.630157\n",
            "[65]\tvalid_0's f1: 0.630517\n",
            "[66]\tvalid_0's f1: 0.630466\n",
            "[67]\tvalid_0's f1: 0.630358\n",
            "[68]\tvalid_0's f1: 0.630397\n",
            "[69]\tvalid_0's f1: 0.630406\n",
            "[70]\tvalid_0's f1: 0.63066\n",
            "[71]\tvalid_0's f1: 0.630934\n",
            "[72]\tvalid_0's f1: 0.63069\n",
            "[73]\tvalid_0's f1: 0.631154\n",
            "[74]\tvalid_0's f1: 0.630861\n",
            "[75]\tvalid_0's f1: 0.631226\n",
            "[76]\tvalid_0's f1: 0.63125\n",
            "[77]\tvalid_0's f1: 0.631195\n",
            "[78]\tvalid_0's f1: 0.631516\n",
            "[79]\tvalid_0's f1: 0.631579\n",
            "[80]\tvalid_0's f1: 0.631902\n",
            "[81]\tvalid_0's f1: 0.632122\n",
            "[82]\tvalid_0's f1: 0.632308\n",
            "[83]\tvalid_0's f1: 0.632485\n",
            "[84]\tvalid_0's f1: 0.632585\n",
            "[85]\tvalid_0's f1: 0.633008\n",
            "[86]\tvalid_0's f1: 0.632998\n",
            "[87]\tvalid_0's f1: 0.633129\n",
            "[88]\tvalid_0's f1: 0.633287\n",
            "[89]\tvalid_0's f1: 0.633533\n",
            "[90]\tvalid_0's f1: 0.633595\n",
            "[91]\tvalid_0's f1: 0.633505\n",
            "[92]\tvalid_0's f1: 0.633386\n",
            "[93]\tvalid_0's f1: 0.633445\n",
            "[94]\tvalid_0's f1: 0.633463\n",
            "[95]\tvalid_0's f1: 0.63304\n",
            "[96]\tvalid_0's f1: 0.633462\n",
            "[97]\tvalid_0's f1: 0.633362\n",
            "[98]\tvalid_0's f1: 0.633674\n",
            "[99]\tvalid_0's f1: 0.633706\n",
            "[100]\tvalid_0's f1: 0.633898\n",
            "[101]\tvalid_0's f1: 0.633984\n",
            "[102]\tvalid_0's f1: 0.634178\n",
            "[103]\tvalid_0's f1: 0.634418\n",
            "[104]\tvalid_0's f1: 0.634707\n",
            "[105]\tvalid_0's f1: 0.634699\n",
            "[106]\tvalid_0's f1: 0.63476\n",
            "[107]\tvalid_0's f1: 0.634658\n",
            "[108]\tvalid_0's f1: 0.635062\n",
            "[109]\tvalid_0's f1: 0.634896\n",
            "[110]\tvalid_0's f1: 0.635077\n",
            "[111]\tvalid_0's f1: 0.635057\n",
            "[112]\tvalid_0's f1: 0.635537\n",
            "[113]\tvalid_0's f1: 0.635536\n",
            "[114]\tvalid_0's f1: 0.635818\n",
            "[115]\tvalid_0's f1: 0.635998\n",
            "[116]\tvalid_0's f1: 0.636194\n",
            "[117]\tvalid_0's f1: 0.63632\n",
            "[118]\tvalid_0's f1: 0.636311\n",
            "[119]\tvalid_0's f1: 0.636172\n",
            "[120]\tvalid_0's f1: 0.636331\n",
            "[121]\tvalid_0's f1: 0.636502\n",
            "[122]\tvalid_0's f1: 0.636149\n",
            "[123]\tvalid_0's f1: 0.636389\n",
            "[124]\tvalid_0's f1: 0.636324\n",
            "[125]\tvalid_0's f1: 0.636376\n",
            "[126]\tvalid_0's f1: 0.636632\n",
            "[127]\tvalid_0's f1: 0.636535\n",
            "[128]\tvalid_0's f1: 0.636565\n",
            "[129]\tvalid_0's f1: 0.63653\n",
            "[130]\tvalid_0's f1: 0.636555\n",
            "[131]\tvalid_0's f1: 0.636429\n",
            "[132]\tvalid_0's f1: 0.636339\n",
            "[133]\tvalid_0's f1: 0.63639\n",
            "[134]\tvalid_0's f1: 0.636624\n",
            "[135]\tvalid_0's f1: 0.636654\n",
            "[136]\tvalid_0's f1: 0.636902\n",
            "[137]\tvalid_0's f1: 0.637125\n",
            "[138]\tvalid_0's f1: 0.637132\n",
            "[139]\tvalid_0's f1: 0.637334\n",
            "[140]\tvalid_0's f1: 0.637241\n",
            "[141]\tvalid_0's f1: 0.637204\n",
            "[142]\tvalid_0's f1: 0.637297\n",
            "[143]\tvalid_0's f1: 0.637113\n",
            "[144]\tvalid_0's f1: 0.63732\n",
            "[145]\tvalid_0's f1: 0.637238\n",
            "[146]\tvalid_0's f1: 0.63756\n",
            "[147]\tvalid_0's f1: 0.637626\n",
            "[148]\tvalid_0's f1: 0.637837\n",
            "[149]\tvalid_0's f1: 0.637741\n",
            "[150]\tvalid_0's f1: 0.637649\n",
            "[151]\tvalid_0's f1: 0.637708\n",
            "[152]\tvalid_0's f1: 0.637627\n",
            "[153]\tvalid_0's f1: 0.637688\n",
            "[154]\tvalid_0's f1: 0.637506\n",
            "[155]\tvalid_0's f1: 0.637451\n",
            "[156]\tvalid_0's f1: 0.637307\n",
            "[157]\tvalid_0's f1: 0.637711\n",
            "[158]\tvalid_0's f1: 0.637617\n",
            "[159]\tvalid_0's f1: 0.637748\n",
            "[160]\tvalid_0's f1: 0.637447\n",
            "[161]\tvalid_0's f1: 0.637366\n",
            "[162]\tvalid_0's f1: 0.637433\n",
            "[163]\tvalid_0's f1: 0.637693\n",
            "[164]\tvalid_0's f1: 0.637589\n",
            "[165]\tvalid_0's f1: 0.637769\n",
            "[166]\tvalid_0's f1: 0.637743\n",
            "[167]\tvalid_0's f1: 0.637742\n",
            "[168]\tvalid_0's f1: 0.637916\n",
            "[169]\tvalid_0's f1: 0.63804\n",
            "[170]\tvalid_0's f1: 0.638173\n",
            "[171]\tvalid_0's f1: 0.638153\n",
            "[172]\tvalid_0's f1: 0.63817\n",
            "[173]\tvalid_0's f1: 0.638311\n",
            "[174]\tvalid_0's f1: 0.638336\n",
            "[175]\tvalid_0's f1: 0.638614\n",
            "[176]\tvalid_0's f1: 0.638803\n",
            "[177]\tvalid_0's f1: 0.638922\n",
            "[178]\tvalid_0's f1: 0.638674\n",
            "[179]\tvalid_0's f1: 0.638702\n",
            "[180]\tvalid_0's f1: 0.638649\n",
            "[181]\tvalid_0's f1: 0.638467\n",
            "[182]\tvalid_0's f1: 0.638685\n",
            "[183]\tvalid_0's f1: 0.638883\n",
            "[184]\tvalid_0's f1: 0.638892\n",
            "[185]\tvalid_0's f1: 0.63897\n",
            "[186]\tvalid_0's f1: 0.638715\n",
            "[187]\tvalid_0's f1: 0.638754\n",
            "[188]\tvalid_0's f1: 0.638766\n",
            "[189]\tvalid_0's f1: 0.638686\n",
            "[190]\tvalid_0's f1: 0.638739\n",
            "[191]\tvalid_0's f1: 0.638858\n",
            "[192]\tvalid_0's f1: 0.639061\n",
            "[193]\tvalid_0's f1: 0.639228\n",
            "[194]\tvalid_0's f1: 0.639105\n",
            "[195]\tvalid_0's f1: 0.638992\n",
            "[196]\tvalid_0's f1: 0.639054\n",
            "[197]\tvalid_0's f1: 0.639152\n",
            "[198]\tvalid_0's f1: 0.639183\n",
            "[199]\tvalid_0's f1: 0.639411\n",
            "[200]\tvalid_0's f1: 0.639375\n",
            "[201]\tvalid_0's f1: 0.639279\n",
            "[202]\tvalid_0's f1: 0.639318\n",
            "[203]\tvalid_0's f1: 0.639403\n",
            "[204]\tvalid_0's f1: 0.639588\n",
            "[205]\tvalid_0's f1: 0.639404\n",
            "[206]\tvalid_0's f1: 0.63955\n",
            "[207]\tvalid_0's f1: 0.639636\n",
            "[208]\tvalid_0's f1: 0.639665\n",
            "[209]\tvalid_0's f1: 0.639668\n",
            "[210]\tvalid_0's f1: 0.639842\n",
            "[211]\tvalid_0's f1: 0.639738\n",
            "[212]\tvalid_0's f1: 0.639905\n",
            "[213]\tvalid_0's f1: 0.639941\n",
            "[214]\tvalid_0's f1: 0.640057\n",
            "[215]\tvalid_0's f1: 0.640068\n",
            "[216]\tvalid_0's f1: 0.640203\n",
            "[217]\tvalid_0's f1: 0.640202\n",
            "[218]\tvalid_0's f1: 0.640187\n",
            "[219]\tvalid_0's f1: 0.640195\n",
            "[220]\tvalid_0's f1: 0.640164\n",
            "[221]\tvalid_0's f1: 0.640259\n",
            "[222]\tvalid_0's f1: 0.640269\n",
            "[223]\tvalid_0's f1: 0.640392\n",
            "[224]\tvalid_0's f1: 0.64038\n",
            "[225]\tvalid_0's f1: 0.640415\n",
            "[226]\tvalid_0's f1: 0.640539\n",
            "[227]\tvalid_0's f1: 0.64049\n",
            "[228]\tvalid_0's f1: 0.640405\n",
            "[229]\tvalid_0's f1: 0.640447\n",
            "[230]\tvalid_0's f1: 0.640474\n",
            "[231]\tvalid_0's f1: 0.64058\n",
            "[232]\tvalid_0's f1: 0.640824\n",
            "[233]\tvalid_0's f1: 0.641094\n",
            "[234]\tvalid_0's f1: 0.641021\n",
            "[235]\tvalid_0's f1: 0.641087\n",
            "[236]\tvalid_0's f1: 0.64106\n",
            "[237]\tvalid_0's f1: 0.640966\n",
            "[238]\tvalid_0's f1: 0.640794\n",
            "[239]\tvalid_0's f1: 0.640709\n",
            "[240]\tvalid_0's f1: 0.640651\n",
            "[241]\tvalid_0's f1: 0.640733\n",
            "[242]\tvalid_0's f1: 0.640853\n",
            "[243]\tvalid_0's f1: 0.64086\n",
            "[244]\tvalid_0's f1: 0.640838\n",
            "[245]\tvalid_0's f1: 0.640854\n",
            "[246]\tvalid_0's f1: 0.640877\n",
            "[247]\tvalid_0's f1: 0.640857\n",
            "[248]\tvalid_0's f1: 0.640974\n",
            "[249]\tvalid_0's f1: 0.6411\n",
            "[250]\tvalid_0's f1: 0.641209\n",
            "[251]\tvalid_0's f1: 0.641127\n",
            "[252]\tvalid_0's f1: 0.641093\n",
            "[253]\tvalid_0's f1: 0.641156\n",
            "[254]\tvalid_0's f1: 0.641112\n",
            "[255]\tvalid_0's f1: 0.641015\n",
            "[256]\tvalid_0's f1: 0.64093\n",
            "[257]\tvalid_0's f1: 0.640802\n",
            "[258]\tvalid_0's f1: 0.640674\n",
            "[259]\tvalid_0's f1: 0.64083\n",
            "[260]\tvalid_0's f1: 0.641139\n",
            "[261]\tvalid_0's f1: 0.641231\n",
            "[262]\tvalid_0's f1: 0.641275\n",
            "[263]\tvalid_0's f1: 0.641109\n",
            "[264]\tvalid_0's f1: 0.64116\n",
            "[265]\tvalid_0's f1: 0.641489\n",
            "[266]\tvalid_0's f1: 0.641502\n",
            "[267]\tvalid_0's f1: 0.641421\n",
            "[268]\tvalid_0's f1: 0.641446\n",
            "[269]\tvalid_0's f1: 0.641615\n",
            "[270]\tvalid_0's f1: 0.641731\n",
            "[271]\tvalid_0's f1: 0.641749\n",
            "[272]\tvalid_0's f1: 0.641709\n",
            "[273]\tvalid_0's f1: 0.64175\n",
            "[274]\tvalid_0's f1: 0.641693\n",
            "[275]\tvalid_0's f1: 0.641696\n",
            "[276]\tvalid_0's f1: 0.641917\n",
            "[277]\tvalid_0's f1: 0.641846\n",
            "[278]\tvalid_0's f1: 0.641753\n",
            "[279]\tvalid_0's f1: 0.641861\n",
            "[280]\tvalid_0's f1: 0.641932\n",
            "[281]\tvalid_0's f1: 0.641913\n",
            "[282]\tvalid_0's f1: 0.641844\n",
            "[283]\tvalid_0's f1: 0.641918\n",
            "[284]\tvalid_0's f1: 0.641974\n",
            "[285]\tvalid_0's f1: 0.641999\n",
            "[286]\tvalid_0's f1: 0.641955\n",
            "[287]\tvalid_0's f1: 0.642007\n",
            "[288]\tvalid_0's f1: 0.642147\n",
            "[289]\tvalid_0's f1: 0.642261\n",
            "[290]\tvalid_0's f1: 0.64213\n",
            "[291]\tvalid_0's f1: 0.642162\n",
            "[292]\tvalid_0's f1: 0.642128\n",
            "[293]\tvalid_0's f1: 0.642066\n",
            "[294]\tvalid_0's f1: 0.641849\n",
            "[295]\tvalid_0's f1: 0.641829\n",
            "[296]\tvalid_0's f1: 0.641758\n",
            "[297]\tvalid_0's f1: 0.641945\n",
            "[298]\tvalid_0's f1: 0.642024\n",
            "[299]\tvalid_0's f1: 0.642093\n",
            "[300]\tvalid_0's f1: 0.641934\n",
            "[301]\tvalid_0's f1: 0.642075\n",
            "[302]\tvalid_0's f1: 0.642034\n",
            "[303]\tvalid_0's f1: 0.641924\n",
            "[304]\tvalid_0's f1: 0.642028\n",
            "[305]\tvalid_0's f1: 0.642096\n",
            "[306]\tvalid_0's f1: 0.642201\n",
            "[307]\tvalid_0's f1: 0.641954\n",
            "[308]\tvalid_0's f1: 0.6421\n",
            "[309]\tvalid_0's f1: 0.642249\n",
            "[310]\tvalid_0's f1: 0.642374\n",
            "[311]\tvalid_0's f1: 0.642355\n",
            "[312]\tvalid_0's f1: 0.642351\n",
            "[313]\tvalid_0's f1: 0.642535\n",
            "[314]\tvalid_0's f1: 0.642483\n",
            "[315]\tvalid_0's f1: 0.642528\n",
            "[316]\tvalid_0's f1: 0.642381\n",
            "[317]\tvalid_0's f1: 0.642418\n",
            "[318]\tvalid_0's f1: 0.642331\n",
            "[319]\tvalid_0's f1: 0.642263\n",
            "[320]\tvalid_0's f1: 0.642268\n",
            "[321]\tvalid_0's f1: 0.642282\n",
            "[322]\tvalid_0's f1: 0.642239\n",
            "[323]\tvalid_0's f1: 0.642448\n",
            "[324]\tvalid_0's f1: 0.642569\n",
            "[325]\tvalid_0's f1: 0.642684\n",
            "[326]\tvalid_0's f1: 0.642616\n",
            "[327]\tvalid_0's f1: 0.642535\n",
            "[328]\tvalid_0's f1: 0.642778\n",
            "[329]\tvalid_0's f1: 0.642864\n",
            "[330]\tvalid_0's f1: 0.642852\n",
            "[331]\tvalid_0's f1: 0.642903\n",
            "[332]\tvalid_0's f1: 0.643051\n",
            "[333]\tvalid_0's f1: 0.643203\n",
            "[334]\tvalid_0's f1: 0.643332\n",
            "[335]\tvalid_0's f1: 0.643447\n",
            "[336]\tvalid_0's f1: 0.643502\n",
            "[337]\tvalid_0's f1: 0.643572\n",
            "[338]\tvalid_0's f1: 0.643671\n",
            "[339]\tvalid_0's f1: 0.643556\n",
            "[340]\tvalid_0's f1: 0.643555\n",
            "[341]\tvalid_0's f1: 0.643594\n",
            "[342]\tvalid_0's f1: 0.643542\n",
            "[343]\tvalid_0's f1: 0.643527\n",
            "[344]\tvalid_0's f1: 0.643583\n",
            "[345]\tvalid_0's f1: 0.64353\n",
            "[346]\tvalid_0's f1: 0.643437\n",
            "[347]\tvalid_0's f1: 0.643277\n",
            "[348]\tvalid_0's f1: 0.643234\n",
            "[349]\tvalid_0's f1: 0.6433\n",
            "[350]\tvalid_0's f1: 0.643228\n",
            "[351]\tvalid_0's f1: 0.643205\n",
            "[352]\tvalid_0's f1: 0.643267\n",
            "[353]\tvalid_0's f1: 0.64325\n",
            "[354]\tvalid_0's f1: 0.64347\n",
            "[355]\tvalid_0's f1: 0.643437\n",
            "[356]\tvalid_0's f1: 0.643718\n",
            "[357]\tvalid_0's f1: 0.643562\n",
            "[358]\tvalid_0's f1: 0.643717\n",
            "[359]\tvalid_0's f1: 0.643862\n",
            "[360]\tvalid_0's f1: 0.643739\n",
            "[361]\tvalid_0's f1: 0.643741\n",
            "[362]\tvalid_0's f1: 0.643801\n",
            "[363]\tvalid_0's f1: 0.643804\n",
            "[364]\tvalid_0's f1: 0.643885\n",
            "[365]\tvalid_0's f1: 0.643987\n",
            "[366]\tvalid_0's f1: 0.643981\n",
            "[367]\tvalid_0's f1: 0.644031\n",
            "[368]\tvalid_0's f1: 0.644071\n",
            "[369]\tvalid_0's f1: 0.644026\n",
            "[370]\tvalid_0's f1: 0.64427\n",
            "[371]\tvalid_0's f1: 0.644258\n",
            "[372]\tvalid_0's f1: 0.644318\n",
            "[373]\tvalid_0's f1: 0.644303\n",
            "[374]\tvalid_0's f1: 0.644111\n",
            "[375]\tvalid_0's f1: 0.644087\n",
            "[376]\tvalid_0's f1: 0.644124\n",
            "[377]\tvalid_0's f1: 0.643956\n",
            "[378]\tvalid_0's f1: 0.644114\n",
            "[379]\tvalid_0's f1: 0.644196\n",
            "[380]\tvalid_0's f1: 0.644093\n",
            "[381]\tvalid_0's f1: 0.644241\n",
            "[382]\tvalid_0's f1: 0.64424\n",
            "[383]\tvalid_0's f1: 0.644294\n",
            "[384]\tvalid_0's f1: 0.644468\n",
            "[385]\tvalid_0's f1: 0.644395\n",
            "[386]\tvalid_0's f1: 0.644382\n",
            "[387]\tvalid_0's f1: 0.644371\n",
            "[388]\tvalid_0's f1: 0.644482\n",
            "[389]\tvalid_0's f1: 0.644567\n",
            "[390]\tvalid_0's f1: 0.64457\n",
            "[391]\tvalid_0's f1: 0.644532\n",
            "[392]\tvalid_0's f1: 0.644701\n",
            "[393]\tvalid_0's f1: 0.64472\n",
            "[394]\tvalid_0's f1: 0.64482\n",
            "[395]\tvalid_0's f1: 0.644725\n",
            "[396]\tvalid_0's f1: 0.644617\n",
            "[397]\tvalid_0's f1: 0.644659\n",
            "[398]\tvalid_0's f1: 0.64476\n",
            "[399]\tvalid_0's f1: 0.644822\n",
            "[400]\tvalid_0's f1: 0.644717\n",
            "[401]\tvalid_0's f1: 0.64484\n",
            "[402]\tvalid_0's f1: 0.644844\n",
            "[403]\tvalid_0's f1: 0.644855\n",
            "[404]\tvalid_0's f1: 0.644884\n",
            "[405]\tvalid_0's f1: 0.644887\n",
            "[406]\tvalid_0's f1: 0.644648\n",
            "[407]\tvalid_0's f1: 0.644725\n",
            "[408]\tvalid_0's f1: 0.644629\n",
            "[409]\tvalid_0's f1: 0.64485\n",
            "[410]\tvalid_0's f1: 0.644779\n",
            "[411]\tvalid_0's f1: 0.644812\n",
            "[412]\tvalid_0's f1: 0.644872\n",
            "[413]\tvalid_0's f1: 0.644748\n",
            "[414]\tvalid_0's f1: 0.64487\n",
            "[415]\tvalid_0's f1: 0.64505\n",
            "[416]\tvalid_0's f1: 0.645053\n",
            "[417]\tvalid_0's f1: 0.644995\n",
            "[418]\tvalid_0's f1: 0.645143\n",
            "[419]\tvalid_0's f1: 0.645335\n",
            "[420]\tvalid_0's f1: 0.64548\n",
            "[421]\tvalid_0's f1: 0.645491\n",
            "[422]\tvalid_0's f1: 0.64532\n",
            "[423]\tvalid_0's f1: 0.645432\n",
            "[424]\tvalid_0's f1: 0.645527\n",
            "[425]\tvalid_0's f1: 0.645387\n",
            "[426]\tvalid_0's f1: 0.645405\n",
            "[427]\tvalid_0's f1: 0.645392\n",
            "[428]\tvalid_0's f1: 0.645341\n",
            "[429]\tvalid_0's f1: 0.645491\n",
            "[430]\tvalid_0's f1: 0.645453\n",
            "[431]\tvalid_0's f1: 0.645529\n",
            "[432]\tvalid_0's f1: 0.645418\n",
            "[433]\tvalid_0's f1: 0.645398\n",
            "[434]\tvalid_0's f1: 0.645405\n",
            "[435]\tvalid_0's f1: 0.645524\n",
            "[436]\tvalid_0's f1: 0.64551\n",
            "[437]\tvalid_0's f1: 0.645577\n",
            "[438]\tvalid_0's f1: 0.645537\n",
            "[439]\tvalid_0's f1: 0.645545\n",
            "[440]\tvalid_0's f1: 0.645588\n",
            "[441]\tvalid_0's f1: 0.645636\n",
            "[442]\tvalid_0's f1: 0.645467\n",
            "[443]\tvalid_0's f1: 0.645545\n",
            "[444]\tvalid_0's f1: 0.645384\n",
            "[445]\tvalid_0's f1: 0.645458\n",
            "[446]\tvalid_0's f1: 0.645515\n",
            "[447]\tvalid_0's f1: 0.645531\n",
            "[448]\tvalid_0's f1: 0.645734\n",
            "[449]\tvalid_0's f1: 0.645765\n",
            "[450]\tvalid_0's f1: 0.645735\n",
            "[451]\tvalid_0's f1: 0.645707\n",
            "[452]\tvalid_0's f1: 0.645555\n",
            "[453]\tvalid_0's f1: 0.645536\n",
            "[454]\tvalid_0's f1: 0.645458\n",
            "[455]\tvalid_0's f1: 0.645481\n",
            "[456]\tvalid_0's f1: 0.645483\n",
            "[457]\tvalid_0's f1: 0.645438\n",
            "[458]\tvalid_0's f1: 0.645454\n",
            "[459]\tvalid_0's f1: 0.645736\n",
            "[460]\tvalid_0's f1: 0.645792\n",
            "[461]\tvalid_0's f1: 0.64581\n",
            "[462]\tvalid_0's f1: 0.645797\n",
            "[463]\tvalid_0's f1: 0.645826\n",
            "[464]\tvalid_0's f1: 0.645858\n",
            "[465]\tvalid_0's f1: 0.645759\n",
            "[466]\tvalid_0's f1: 0.64578\n",
            "[467]\tvalid_0's f1: 0.64574\n",
            "[468]\tvalid_0's f1: 0.645864\n",
            "[469]\tvalid_0's f1: 0.645877\n",
            "[470]\tvalid_0's f1: 0.645734\n",
            "[471]\tvalid_0's f1: 0.6456\n",
            "[472]\tvalid_0's f1: 0.645515\n",
            "[473]\tvalid_0's f1: 0.645522\n",
            "[474]\tvalid_0's f1: 0.645566\n",
            "[475]\tvalid_0's f1: 0.645637\n",
            "[476]\tvalid_0's f1: 0.645729\n",
            "[477]\tvalid_0's f1: 0.645762\n",
            "[478]\tvalid_0's f1: 0.645702\n",
            "[479]\tvalid_0's f1: 0.645745\n",
            "[480]\tvalid_0's f1: 0.645692\n",
            "[481]\tvalid_0's f1: 0.645627\n",
            "[482]\tvalid_0's f1: 0.645639\n",
            "[483]\tvalid_0's f1: 0.645531\n",
            "[484]\tvalid_0's f1: 0.645488\n",
            "[485]\tvalid_0's f1: 0.645483\n",
            "[486]\tvalid_0's f1: 0.645435\n",
            "[487]\tvalid_0's f1: 0.645214\n",
            "[488]\tvalid_0's f1: 0.645222\n",
            "[489]\tvalid_0's f1: 0.64545\n",
            "[490]\tvalid_0's f1: 0.645553\n",
            "[491]\tvalid_0's f1: 0.645571\n",
            "[492]\tvalid_0's f1: 0.64564\n",
            "[493]\tvalid_0's f1: 0.645651\n",
            "[494]\tvalid_0's f1: 0.645429\n",
            "[495]\tvalid_0's f1: 0.645469\n",
            "[496]\tvalid_0's f1: 0.645542\n",
            "[497]\tvalid_0's f1: 0.645684\n",
            "[498]\tvalid_0's f1: 0.645431\n",
            "[499]\tvalid_0's f1: 0.645464\n",
            "[500]\tvalid_0's f1: 0.645502\n",
            "[501]\tvalid_0's f1: 0.645349\n",
            "[502]\tvalid_0's f1: 0.645257\n",
            "[503]\tvalid_0's f1: 0.645252\n",
            "[504]\tvalid_0's f1: 0.645281\n",
            "[505]\tvalid_0's f1: 0.645204\n",
            "[506]\tvalid_0's f1: 0.6452\n",
            "[507]\tvalid_0's f1: 0.645239\n",
            "[508]\tvalid_0's f1: 0.645091\n",
            "[509]\tvalid_0's f1: 0.645135\n",
            "[510]\tvalid_0's f1: 0.64514\n",
            "[511]\tvalid_0's f1: 0.645163\n",
            "[512]\tvalid_0's f1: 0.645238\n",
            "[513]\tvalid_0's f1: 0.64534\n",
            "[514]\tvalid_0's f1: 0.645513\n",
            "[515]\tvalid_0's f1: 0.645564\n",
            "[516]\tvalid_0's f1: 0.645591\n",
            "[517]\tvalid_0's f1: 0.645516\n",
            "[518]\tvalid_0's f1: 0.645768\n",
            "[519]\tvalid_0's f1: 0.645759\n",
            "[520]\tvalid_0's f1: 0.64583\n",
            "[521]\tvalid_0's f1: 0.645998\n",
            "[522]\tvalid_0's f1: 0.646105\n",
            "[523]\tvalid_0's f1: 0.646062\n",
            "[524]\tvalid_0's f1: 0.64615\n",
            "[525]\tvalid_0's f1: 0.646299\n",
            "[526]\tvalid_0's f1: 0.646287\n",
            "[527]\tvalid_0's f1: 0.646408\n",
            "[528]\tvalid_0's f1: 0.646444\n",
            "[529]\tvalid_0's f1: 0.646449\n",
            "[530]\tvalid_0's f1: 0.646494\n",
            "[531]\tvalid_0's f1: 0.646537\n",
            "[532]\tvalid_0's f1: 0.646602\n",
            "[533]\tvalid_0's f1: 0.646668\n",
            "[534]\tvalid_0's f1: 0.646649\n",
            "[535]\tvalid_0's f1: 0.646616\n",
            "[536]\tvalid_0's f1: 0.646617\n",
            "[537]\tvalid_0's f1: 0.646584\n",
            "[538]\tvalid_0's f1: 0.646611\n",
            "[539]\tvalid_0's f1: 0.646561\n",
            "[540]\tvalid_0's f1: 0.646485\n",
            "[541]\tvalid_0's f1: 0.64641\n",
            "[542]\tvalid_0's f1: 0.646487\n",
            "[543]\tvalid_0's f1: 0.646317\n",
            "[544]\tvalid_0's f1: 0.646235\n",
            "[545]\tvalid_0's f1: 0.646216\n",
            "[546]\tvalid_0's f1: 0.646105\n",
            "[547]\tvalid_0's f1: 0.646189\n",
            "[548]\tvalid_0's f1: 0.646307\n",
            "[549]\tvalid_0's f1: 0.64624\n",
            "[550]\tvalid_0's f1: 0.646332\n",
            "[551]\tvalid_0's f1: 0.64649\n",
            "[552]\tvalid_0's f1: 0.646309\n",
            "[553]\tvalid_0's f1: 0.6463\n",
            "[554]\tvalid_0's f1: 0.646344\n",
            "[555]\tvalid_0's f1: 0.646275\n",
            "[556]\tvalid_0's f1: 0.646256\n",
            "[557]\tvalid_0's f1: 0.64641\n",
            "[558]\tvalid_0's f1: 0.64636\n",
            "[559]\tvalid_0's f1: 0.646327\n",
            "[560]\tvalid_0's f1: 0.646429\n",
            "[561]\tvalid_0's f1: 0.646276\n",
            "[562]\tvalid_0's f1: 0.646229\n",
            "[563]\tvalid_0's f1: 0.646273\n",
            "[564]\tvalid_0's f1: 0.646305\n",
            "[565]\tvalid_0's f1: 0.646369\n",
            "[566]\tvalid_0's f1: 0.646335\n",
            "[567]\tvalid_0's f1: 0.646282\n",
            "[568]\tvalid_0's f1: 0.646192\n",
            "[569]\tvalid_0's f1: 0.646212\n",
            "[570]\tvalid_0's f1: 0.646028\n",
            "[571]\tvalid_0's f1: 0.646034\n",
            "[572]\tvalid_0's f1: 0.645979\n",
            "[573]\tvalid_0's f1: 0.64615\n",
            "[574]\tvalid_0's f1: 0.646253\n",
            "[575]\tvalid_0's f1: 0.646204\n",
            "[576]\tvalid_0's f1: 0.646159\n",
            "[577]\tvalid_0's f1: 0.646109\n",
            "[578]\tvalid_0's f1: 0.646101\n",
            "[579]\tvalid_0's f1: 0.646042\n",
            "[580]\tvalid_0's f1: 0.64602\n",
            "[581]\tvalid_0's f1: 0.646033\n",
            "[582]\tvalid_0's f1: 0.646154\n",
            "[583]\tvalid_0's f1: 0.646087\n",
            "[584]\tvalid_0's f1: 0.64621\n",
            "[585]\tvalid_0's f1: 0.646248\n",
            "[586]\tvalid_0's f1: 0.646115\n",
            "[587]\tvalid_0's f1: 0.646102\n",
            "[588]\tvalid_0's f1: 0.646074\n",
            "[589]\tvalid_0's f1: 0.646108\n",
            "[590]\tvalid_0's f1: 0.64612\n",
            "[591]\tvalid_0's f1: 0.646184\n",
            "[592]\tvalid_0's f1: 0.646176\n",
            "[593]\tvalid_0's f1: 0.646202\n",
            "[594]\tvalid_0's f1: 0.646222\n",
            "[595]\tvalid_0's f1: 0.646198\n",
            "[596]\tvalid_0's f1: 0.646403\n",
            "[597]\tvalid_0's f1: 0.646408\n",
            "[598]\tvalid_0's f1: 0.646434\n",
            "[599]\tvalid_0's f1: 0.646318\n",
            "[600]\tvalid_0's f1: 0.646267\n",
            "[601]\tvalid_0's f1: 0.646326\n",
            "[602]\tvalid_0's f1: 0.646407\n",
            "[603]\tvalid_0's f1: 0.646288\n",
            "[604]\tvalid_0's f1: 0.646295\n",
            "[605]\tvalid_0's f1: 0.646424\n",
            "[606]\tvalid_0's f1: 0.646419\n",
            "[607]\tvalid_0's f1: 0.646462\n",
            "[608]\tvalid_0's f1: 0.646437\n",
            "[609]\tvalid_0's f1: 0.646507\n",
            "[610]\tvalid_0's f1: 0.646571\n",
            "[611]\tvalid_0's f1: 0.646577\n",
            "[612]\tvalid_0's f1: 0.64662\n",
            "[613]\tvalid_0's f1: 0.646654\n",
            "[614]\tvalid_0's f1: 0.646762\n",
            "[615]\tvalid_0's f1: 0.646698\n",
            "[616]\tvalid_0's f1: 0.646731\n",
            "[617]\tvalid_0's f1: 0.646806\n",
            "[618]\tvalid_0's f1: 0.6468\n",
            "[619]\tvalid_0's f1: 0.646845\n",
            "[620]\tvalid_0's f1: 0.646918\n",
            "[621]\tvalid_0's f1: 0.646908\n",
            "[622]\tvalid_0's f1: 0.646973\n",
            "[623]\tvalid_0's f1: 0.647048\n",
            "[624]\tvalid_0's f1: 0.646914\n",
            "[625]\tvalid_0's f1: 0.646817\n",
            "[626]\tvalid_0's f1: 0.646924\n",
            "[627]\tvalid_0's f1: 0.646809\n",
            "[628]\tvalid_0's f1: 0.646861\n",
            "[629]\tvalid_0's f1: 0.646881\n",
            "[630]\tvalid_0's f1: 0.646812\n",
            "[631]\tvalid_0's f1: 0.647055\n",
            "[632]\tvalid_0's f1: 0.647017\n",
            "[633]\tvalid_0's f1: 0.64711\n",
            "[634]\tvalid_0's f1: 0.647142\n",
            "[635]\tvalid_0's f1: 0.647015\n",
            "[636]\tvalid_0's f1: 0.646982\n",
            "[637]\tvalid_0's f1: 0.647079\n",
            "[638]\tvalid_0's f1: 0.647097\n",
            "[639]\tvalid_0's f1: 0.647225\n",
            "[640]\tvalid_0's f1: 0.647373\n",
            "[641]\tvalid_0's f1: 0.647263\n",
            "[642]\tvalid_0's f1: 0.647321\n",
            "[643]\tvalid_0's f1: 0.647429\n",
            "[644]\tvalid_0's f1: 0.647309\n",
            "[645]\tvalid_0's f1: 0.647269\n",
            "[646]\tvalid_0's f1: 0.647182\n",
            "[647]\tvalid_0's f1: 0.647055\n",
            "[648]\tvalid_0's f1: 0.647006\n",
            "[649]\tvalid_0's f1: 0.646985\n",
            "[650]\tvalid_0's f1: 0.647023\n",
            "[651]\tvalid_0's f1: 0.646995\n",
            "[652]\tvalid_0's f1: 0.647054\n",
            "[653]\tvalid_0's f1: 0.647131\n",
            "[654]\tvalid_0's f1: 0.647145\n",
            "[655]\tvalid_0's f1: 0.647069\n",
            "[656]\tvalid_0's f1: 0.647163\n",
            "[657]\tvalid_0's f1: 0.646998\n",
            "[658]\tvalid_0's f1: 0.646957\n",
            "[659]\tvalid_0's f1: 0.646902\n",
            "[660]\tvalid_0's f1: 0.646844\n",
            "[661]\tvalid_0's f1: 0.646818\n",
            "[662]\tvalid_0's f1: 0.646945\n",
            "[663]\tvalid_0's f1: 0.646895\n",
            "[664]\tvalid_0's f1: 0.646804\n",
            "[665]\tvalid_0's f1: 0.646909\n",
            "[666]\tvalid_0's f1: 0.646837\n",
            "[667]\tvalid_0's f1: 0.646869\n",
            "[668]\tvalid_0's f1: 0.646875\n",
            "[669]\tvalid_0's f1: 0.64684\n",
            "[670]\tvalid_0's f1: 0.64681\n",
            "[671]\tvalid_0's f1: 0.646865\n",
            "[672]\tvalid_0's f1: 0.646836\n",
            "[673]\tvalid_0's f1: 0.646996\n",
            "[674]\tvalid_0's f1: 0.646983\n",
            "[675]\tvalid_0's f1: 0.646993\n",
            "[676]\tvalid_0's f1: 0.647071\n",
            "[677]\tvalid_0's f1: 0.647041\n",
            "[678]\tvalid_0's f1: 0.647071\n",
            "[679]\tvalid_0's f1: 0.647186\n",
            "[680]\tvalid_0's f1: 0.647181\n",
            "[681]\tvalid_0's f1: 0.647168\n",
            "[682]\tvalid_0's f1: 0.647213\n",
            "[683]\tvalid_0's f1: 0.64713\n",
            "[684]\tvalid_0's f1: 0.647175\n",
            "[685]\tvalid_0's f1: 0.647113\n",
            "[686]\tvalid_0's f1: 0.647044\n",
            "[687]\tvalid_0's f1: 0.647012\n",
            "[688]\tvalid_0's f1: 0.64696\n",
            "[689]\tvalid_0's f1: 0.646929\n",
            "[690]\tvalid_0's f1: 0.64696\n",
            "[691]\tvalid_0's f1: 0.646952\n",
            "[692]\tvalid_0's f1: 0.646976\n",
            "[693]\tvalid_0's f1: 0.646956\n",
            "[694]\tvalid_0's f1: 0.646858\n",
            "[695]\tvalid_0's f1: 0.646921\n",
            "[696]\tvalid_0's f1: 0.646984\n",
            "[697]\tvalid_0's f1: 0.64701\n",
            "[698]\tvalid_0's f1: 0.647044\n",
            "[699]\tvalid_0's f1: 0.647012\n",
            "[700]\tvalid_0's f1: 0.647051\n",
            "[701]\tvalid_0's f1: 0.646981\n",
            "[702]\tvalid_0's f1: 0.646951\n",
            "[703]\tvalid_0's f1: 0.646924\n",
            "[704]\tvalid_0's f1: 0.64692\n",
            "[705]\tvalid_0's f1: 0.646987\n",
            "[706]\tvalid_0's f1: 0.647017\n",
            "[707]\tvalid_0's f1: 0.646968\n",
            "[708]\tvalid_0's f1: 0.646993\n",
            "[709]\tvalid_0's f1: 0.646998\n",
            "[710]\tvalid_0's f1: 0.647043\n",
            "[711]\tvalid_0's f1: 0.647145\n",
            "[712]\tvalid_0's f1: 0.647316\n",
            "[713]\tvalid_0's f1: 0.647277\n",
            "[714]\tvalid_0's f1: 0.64735\n",
            "[715]\tvalid_0's f1: 0.64732\n",
            "[716]\tvalid_0's f1: 0.647307\n",
            "[717]\tvalid_0's f1: 0.647424\n",
            "[718]\tvalid_0's f1: 0.647261\n",
            "[719]\tvalid_0's f1: 0.647267\n",
            "[720]\tvalid_0's f1: 0.6473\n",
            "[721]\tvalid_0's f1: 0.647243\n",
            "[722]\tvalid_0's f1: 0.647121\n",
            "[723]\tvalid_0's f1: 0.64716\n",
            "[724]\tvalid_0's f1: 0.647081\n",
            "[725]\tvalid_0's f1: 0.64712\n",
            "[726]\tvalid_0's f1: 0.647103\n",
            "[727]\tvalid_0's f1: 0.647026\n",
            "[728]\tvalid_0's f1: 0.647091\n",
            "[729]\tvalid_0's f1: 0.647161\n",
            "[730]\tvalid_0's f1: 0.647117\n",
            "[731]\tvalid_0's f1: 0.647226\n",
            "[732]\tvalid_0's f1: 0.647213\n",
            "[733]\tvalid_0's f1: 0.647142\n",
            "[734]\tvalid_0's f1: 0.64718\n",
            "[735]\tvalid_0's f1: 0.647277\n",
            "[736]\tvalid_0's f1: 0.647245\n",
            "[737]\tvalid_0's f1: 0.647181\n",
            "[738]\tvalid_0's f1: 0.647162\n",
            "[739]\tvalid_0's f1: 0.647213\n",
            "[740]\tvalid_0's f1: 0.647237\n",
            "[741]\tvalid_0's f1: 0.647255\n",
            "[742]\tvalid_0's f1: 0.647244\n",
            "[743]\tvalid_0's f1: 0.647232\n",
            "Early stopping, best iteration is:\n",
            "[643]\tvalid_0's f1: 0.647429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_prob = lgb2.predict( test )\n",
        "ypred = np.around(lgb_prob).astype(int)\n",
        "#print(ypred)"
      ],
      "metadata": {
        "id": "RBnTGnZqH3kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-go8cH7CIDsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost / metric = f1-score \n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import f1_score\n",
        "from bayes_opt import BayesianOptimization\n",
        "n_folds=5\n",
        "d_train = xgb.DMatrix(X_train, y_train)\n",
        "d_val = xgb.DMatrix(X_test,y_test)\n",
        "\n",
        "param_test ={'num_leaves': (6,45),\n",
        "             'min_child_weight': (1e-3, 1e3), #0.001 ~ 1000\n",
        "             'subsample': (0.5,1), \n",
        "             'colsample_bytree': (0.2,1), \n",
        "             'reg_alpha': (0, 100),\n",
        "             'reg_lambda': (0, 100),\n",
        "             'learning_rate': (0.01,0.2),\n",
        "             'max_depth': (3,8)}\n",
        "\n",
        "def xgb_f1_score(y_hat, data):\n",
        "    y_true = data.get_label().astype(int)\n",
        "#    y_hat = (y_hat >= 0.5)\n",
        "    y_hat = np.round(y_hat).astype(int) # scikits f1 doesn't like probabilities\n",
        "    return 'f1', f1_score(y_true, y_hat)\n",
        "\n",
        "\n",
        "def xgb_cv(num_leaves,min_child_weight,subsample,colsample_bytree,reg_alpha,reg_lambda,max_depth,learning_rate):\n",
        "    params = {'nrounds' : 5000, #num_iteration\n",
        "             'early_stopping_rounds':30, #30에서 변경\n",
        "             'n_jobs':-1\n",
        "#              'metric' : 'custom', #xgb랑 lgb랑 다름\n",
        "             }\n",
        "    params['num_leaves'] = int(round(num_leaves))\n",
        "    params['min_child_weight'] = min_child_weight\n",
        "    params['subsample'] = subsample\n",
        "    params['colsample_bytree'] = colsample_bytree\n",
        "    params['reg_alpha'] = reg_alpha\n",
        "    params['reg_lambda'] = reg_lambda\n",
        "    params['learning_rate'] = learning_rate\n",
        "    params['max_depth']= int(round(max_depth))\n",
        "    xgbcv = xgb.cv(params, d_train, nfold=n_folds, seed=42, stratified=True, verbose_eval = 200,\n",
        "                    feval=xgb_f1_score)\n",
        "    \n",
        "    mean_f1 = xgbcv[\"test-f1-mean\"].values[-1]\n",
        "    \n",
        "    return mean_f1\n",
        "  \n",
        "lgbB1 = BayesianOptimization(xgb_cv,param_test,random_state=42,verbose=2)\n",
        "init_round=5\n",
        "opt_round = 10\n",
        "lgbB1.maximize(init_points=init_round, n_iter=opt_round) # n_iter 찾아보기?\n",
        "print(lgbB1.max)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "UUomRGkbtHCI",
        "outputId": "6390ee8d-3553-4f9c-9b50-e19b5b167392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------\n",
            "[0]\ttrain-f1:0.57716+0.0105127\ttrain-rmse:0.496479+3.68054e-05\ttest-f1:0.573663+0.00963472\ttest-rmse:0.496566+6.24083e-05\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: (0.49963209507789, 0.19063571821788408, 6.659969709057025, 598.6588855385523, 12.084726977255023, 15.599452033620265, 5.8083612168199465, 0.9330880728874675)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-0c757c8a1a82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0minit_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mopt_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mlgbB1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_round\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# n_iter 찾아보기?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgbB1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-0c757c8a1a82>\u001b[0m in \u001b[0;36mxgb_cv\u001b[0;34m(num_leaves, min_child_weight, subsample, colsample_bytree, reg_alpha, reg_lambda, max_depth, learning_rate)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     xgbcv = xgb.cv(params, d_train, nfold=n_folds, seed=42, stratified=True, verbose_eval = 200,\n\u001b[0;32m---> 41\u001b[0;31m                     feval=xgb_f1_score)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmean_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgbcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test-f1-mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    443\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params={'colsample_bytree': 0.9689, 'learning_rate': 0.01936, 'max_depth': 3, 'min_child_weight': 618.567, 'num_leaves': 14, 'reg_alpha': 58.5531, 'reg_lambda': 0.2868, 'subsample': 0.7281}"
      ],
      "metadata": {
        "id": "-6q7zP72DTm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = {'num_iterations' : 5000, 'early_stopping_rounds':100, 'n_jobs':-1, 'metric' : 'custom', 'verbose': 100, 'seed' : 42} #원래 있던 파라미터들 추가, early_stopping만 100으로 변경\n",
        "xgb_params.update(a)\n",
        "d_train = xgb.DMatrix(X_train, y_train)\n",
        "d_test = xgb.DMatrix(X_test,y_test)\n",
        "watch_list = [(d_test, 'eval'), (d_train, 'train')]\n",
        "xgb2 = xgb.train(xgb_params, d_train, evals = watch_list, feval=xgb_f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UTRMbnPD1qm",
        "outputId": "d312e839-6590-44f7-a6d9-b8ad8ad0e0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\teval-rmse:0.499661\ttrain-rmse:0.499677\teval-f1:0.642685\ttrain-f1:0.641215\n",
            "[1]\teval-rmse:0.49934\ttrain-rmse:0.499347\teval-f1:0.642678\ttrain-f1:0.641199\n",
            "[2]\teval-rmse:0.499057\ttrain-rmse:0.499071\teval-f1:0.642678\ttrain-f1:0.641199\n",
            "[3]\teval-rmse:0.49874\ttrain-rmse:0.498713\teval-f1:0.642678\ttrain-f1:0.641199\n",
            "[4]\teval-rmse:0.498468\ttrain-rmse:0.498439\teval-f1:0.642678\ttrain-f1:0.641199\n",
            "[5]\teval-rmse:0.498152\ttrain-rmse:0.498232\teval-f1:0.642678\ttrain-f1:0.641199\n",
            "[6]\teval-rmse:0.497941\ttrain-rmse:0.497899\teval-f1:0.642678\ttrain-f1:0.641199\n",
            "[7]\teval-rmse:0.497655\ttrain-rmse:0.497588\teval-f1:0.642678\ttrain-f1:0.641199\n",
            "[8]\teval-rmse:0.497402\ttrain-rmse:0.497304\teval-f1:0.642678\ttrain-f1:0.641199\n",
            "[9]\teval-rmse:0.497192\ttrain-rmse:0.497114\teval-f1:0.641011\ttrain-f1:0.639746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test data 변경\n",
        "\n",
        "#int type category로 변경\n",
        "# for i in enumerate(cate):\n",
        "#     ca = i[1]\n",
        "#     test[ca] = test[ca].astype('category') \n",
        "\n",
        "#test데이타 예측\n",
        "dtest = xgb.DMatrix(test)\n",
        "xgb_prob = xgb2.predict( dtest )"
      ],
      "metadata": {
        "id": "ddLjsIsmSn8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_prob # predict 한게 저렇게 나오는게 맞나..? 0.5이상이면 1, 아님 0 해야겟지..?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeRjngoMGYrK",
        "outputId": "ab32ff09-bb6e-4d84-cefc-7e53758d5e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.50657856, 0.48306903, 0.47263995, ..., 0.5199679 , 0.5199679 ,\n",
              "       0.5199679 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.around(xgb_prob).astype(int)"
      ],
      "metadata": {
        "id": "rKPE2gK6MwQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLFigfRoNR7W",
        "outputId": "07fa524f-4538-4dab-b8e2-64f1a3c90c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#catboost\n",
        "! pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QpoVjNaVbjJ",
        "outputId": "8fd39ac9-357b-4ab0-9668-968ce1be8155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.6)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import Pool, CatBoostClassifier\n",
        "import catboost as cb\n",
        "model_cb = CatBoostClassifier(task_type='CPU', iterations = 150,\n",
        "                              random_state = 42, \n",
        "                              eval_metric=\"F1\")"
      ],
      "metadata": {
        "id": "ekDYugjNVuln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cb.fit(X_train, y_train, cat_features= cate, plot=True, \n",
        "             eval_set=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "99dd4a7575b74e22bedc8f436cd7e7c8"
          ]
        },
        "id": "rpIna4GWWEr6",
        "outputId": "65a1c9e9-f49d-4253-c61b-85f70b6692de"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99dd4a7575b74e22bedc8f436cd7e7c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.318006\n",
            "0:\tlearn: 0.6250642\ttest: 0.6272690\tbest: 0.6272690 (0)\ttotal: 1.45s\tremaining: 3m 36s\n",
            "1:\tlearn: 0.6075590\ttest: 0.6048413\tbest: 0.6272690 (0)\ttotal: 2.75s\tremaining: 3m 23s\n",
            "2:\tlearn: 0.6129553\ttest: 0.6096984\tbest: 0.6272690 (0)\ttotal: 3.97s\tremaining: 3m 14s\n",
            "3:\tlearn: 0.6145074\ttest: 0.6107206\tbest: 0.6272690 (0)\ttotal: 4.86s\tremaining: 2m 57s\n",
            "4:\tlearn: 0.6148459\ttest: 0.6117961\tbest: 0.6272690 (0)\ttotal: 5.75s\tremaining: 2m 46s\n",
            "5:\tlearn: 0.6179860\ttest: 0.6164480\tbest: 0.6272690 (0)\ttotal: 6.7s\tremaining: 2m 40s\n",
            "6:\tlearn: 0.6184084\ttest: 0.6167516\tbest: 0.6272690 (0)\ttotal: 7.61s\tremaining: 2m 35s\n",
            "7:\tlearn: 0.6198116\ttest: 0.6174293\tbest: 0.6272690 (0)\ttotal: 8.55s\tremaining: 2m 31s\n",
            "8:\tlearn: 0.6195517\ttest: 0.6168640\tbest: 0.6272690 (0)\ttotal: 9.45s\tremaining: 2m 28s\n",
            "9:\tlearn: 0.6208182\ttest: 0.6194179\tbest: 0.6272690 (0)\ttotal: 10.4s\tremaining: 2m 24s\n",
            "10:\tlearn: 0.6217102\ttest: 0.6210618\tbest: 0.6272690 (0)\ttotal: 11.3s\tremaining: 2m 22s\n",
            "11:\tlearn: 0.6224578\ttest: 0.6204700\tbest: 0.6272690 (0)\ttotal: 12.2s\tremaining: 2m 19s\n",
            "12:\tlearn: 0.6240623\ttest: 0.6234766\tbest: 0.6272690 (0)\ttotal: 13.1s\tremaining: 2m 17s\n",
            "13:\tlearn: 0.6244225\ttest: 0.6232926\tbest: 0.6272690 (0)\ttotal: 14s\tremaining: 2m 15s\n",
            "14:\tlearn: 0.6256154\ttest: 0.6247050\tbest: 0.6272690 (0)\ttotal: 14.9s\tremaining: 2m 14s\n",
            "15:\tlearn: 0.6258311\ttest: 0.6249834\tbest: 0.6272690 (0)\ttotal: 15.8s\tremaining: 2m 12s\n",
            "16:\tlearn: 0.6264748\ttest: 0.6254884\tbest: 0.6272690 (0)\ttotal: 16.7s\tremaining: 2m 10s\n",
            "17:\tlearn: 0.6263244\ttest: 0.6249501\tbest: 0.6272690 (0)\ttotal: 17.6s\tremaining: 2m 9s\n",
            "18:\tlearn: 0.6263674\ttest: 0.6256470\tbest: 0.6272690 (0)\ttotal: 18.5s\tremaining: 2m 7s\n",
            "19:\tlearn: 0.6272310\ttest: 0.6258567\tbest: 0.6272690 (0)\ttotal: 19.4s\tremaining: 2m 6s\n",
            "20:\tlearn: 0.6278355\ttest: 0.6269652\tbest: 0.6272690 (0)\ttotal: 20.3s\tremaining: 2m 4s\n",
            "21:\tlearn: 0.6291506\ttest: 0.6276189\tbest: 0.6276189 (21)\ttotal: 21.2s\tremaining: 2m 3s\n",
            "22:\tlearn: 0.6296262\ttest: 0.6289473\tbest: 0.6289473 (22)\ttotal: 22.1s\tremaining: 2m 2s\n",
            "23:\tlearn: 0.6296762\ttest: 0.6289596\tbest: 0.6289596 (23)\ttotal: 23s\tremaining: 2m\n",
            "24:\tlearn: 0.6296669\ttest: 0.6287491\tbest: 0.6289596 (23)\ttotal: 23.9s\tremaining: 1m 59s\n",
            "25:\tlearn: 0.6299175\ttest: 0.6280744\tbest: 0.6289596 (23)\ttotal: 24.8s\tremaining: 1m 58s\n",
            "26:\tlearn: 0.6300679\ttest: 0.6281316\tbest: 0.6289596 (23)\ttotal: 25.8s\tremaining: 1m 57s\n",
            "27:\tlearn: 0.6300047\ttest: 0.6278889\tbest: 0.6289596 (23)\ttotal: 26.7s\tremaining: 1m 56s\n",
            "28:\tlearn: 0.6300930\ttest: 0.6281230\tbest: 0.6289596 (23)\ttotal: 27.6s\tremaining: 1m 55s\n",
            "29:\tlearn: 0.6305559\ttest: 0.6286392\tbest: 0.6289596 (23)\ttotal: 28.5s\tremaining: 1m 54s\n",
            "30:\tlearn: 0.6309273\ttest: 0.6295653\tbest: 0.6295653 (30)\ttotal: 29.4s\tremaining: 1m 53s\n",
            "31:\tlearn: 0.6310627\ttest: 0.6296553\tbest: 0.6296553 (31)\ttotal: 30.4s\tremaining: 1m 52s\n",
            "32:\tlearn: 0.6307222\ttest: 0.6288528\tbest: 0.6296553 (31)\ttotal: 31.3s\tremaining: 1m 51s\n",
            "33:\tlearn: 0.6307418\ttest: 0.6290017\tbest: 0.6296553 (31)\ttotal: 32.3s\tremaining: 1m 50s\n",
            "34:\tlearn: 0.6309535\ttest: 0.6292835\tbest: 0.6296553 (31)\ttotal: 33.2s\tremaining: 1m 48s\n",
            "35:\tlearn: 0.6309677\ttest: 0.6291975\tbest: 0.6296553 (31)\ttotal: 34.1s\tremaining: 1m 47s\n",
            "36:\tlearn: 0.6320138\ttest: 0.6299011\tbest: 0.6299011 (36)\ttotal: 35s\tremaining: 1m 46s\n",
            "37:\tlearn: 0.6318755\ttest: 0.6302005\tbest: 0.6302005 (37)\ttotal: 35.9s\tremaining: 1m 45s\n",
            "38:\tlearn: 0.6318397\ttest: 0.6301724\tbest: 0.6302005 (37)\ttotal: 36.8s\tremaining: 1m 44s\n",
            "39:\tlearn: 0.6321100\ttest: 0.6302785\tbest: 0.6302785 (39)\ttotal: 37.7s\tremaining: 1m 43s\n",
            "40:\tlearn: 0.6320792\ttest: 0.6300839\tbest: 0.6302785 (39)\ttotal: 38.6s\tremaining: 1m 42s\n",
            "41:\tlearn: 0.6322064\ttest: 0.6303511\tbest: 0.6303511 (41)\ttotal: 39.5s\tremaining: 1m 41s\n",
            "42:\tlearn: 0.6322625\ttest: 0.6301479\tbest: 0.6303511 (41)\ttotal: 40.4s\tremaining: 1m 40s\n",
            "43:\tlearn: 0.6324218\ttest: 0.6302668\tbest: 0.6303511 (41)\ttotal: 41.4s\tremaining: 1m 39s\n",
            "44:\tlearn: 0.6325838\ttest: 0.6300537\tbest: 0.6303511 (41)\ttotal: 42.3s\tremaining: 1m 38s\n",
            "45:\tlearn: 0.6326163\ttest: 0.6299947\tbest: 0.6303511 (41)\ttotal: 43.2s\tremaining: 1m 37s\n",
            "46:\tlearn: 0.6327422\ttest: 0.6301346\tbest: 0.6303511 (41)\ttotal: 44.1s\tremaining: 1m 36s\n",
            "47:\tlearn: 0.6331086\ttest: 0.6306176\tbest: 0.6306176 (47)\ttotal: 45s\tremaining: 1m 35s\n",
            "48:\tlearn: 0.6334593\ttest: 0.6309334\tbest: 0.6309334 (48)\ttotal: 45.9s\tremaining: 1m 34s\n",
            "49:\tlearn: 0.6340332\ttest: 0.6315590\tbest: 0.6315590 (49)\ttotal: 46.8s\tremaining: 1m 33s\n",
            "50:\tlearn: 0.6341021\ttest: 0.6318266\tbest: 0.6318266 (50)\ttotal: 47.8s\tremaining: 1m 32s\n",
            "51:\tlearn: 0.6342996\ttest: 0.6321684\tbest: 0.6321684 (51)\ttotal: 48.7s\tremaining: 1m 31s\n",
            "52:\tlearn: 0.6343703\ttest: 0.6319038\tbest: 0.6321684 (51)\ttotal: 49.6s\tremaining: 1m 30s\n",
            "53:\tlearn: 0.6346946\ttest: 0.6316859\tbest: 0.6321684 (51)\ttotal: 50.5s\tremaining: 1m 29s\n",
            "54:\tlearn: 0.6347092\ttest: 0.6314758\tbest: 0.6321684 (51)\ttotal: 51.4s\tremaining: 1m 28s\n",
            "55:\tlearn: 0.6350456\ttest: 0.6317809\tbest: 0.6321684 (51)\ttotal: 52.3s\tremaining: 1m 27s\n",
            "56:\tlearn: 0.6356536\ttest: 0.6320825\tbest: 0.6321684 (51)\ttotal: 53.2s\tremaining: 1m 26s\n",
            "57:\tlearn: 0.6362215\ttest: 0.6329551\tbest: 0.6329551 (57)\ttotal: 54.1s\tremaining: 1m 25s\n",
            "58:\tlearn: 0.6363494\ttest: 0.6333024\tbest: 0.6333024 (58)\ttotal: 55.1s\tremaining: 1m 24s\n",
            "59:\tlearn: 0.6364333\ttest: 0.6328316\tbest: 0.6333024 (58)\ttotal: 56s\tremaining: 1m 24s\n",
            "60:\tlearn: 0.6368467\ttest: 0.6329330\tbest: 0.6333024 (58)\ttotal: 56.9s\tremaining: 1m 22s\n",
            "61:\tlearn: 0.6369489\ttest: 0.6328955\tbest: 0.6333024 (58)\ttotal: 57.8s\tremaining: 1m 22s\n",
            "62:\tlearn: 0.6371163\ttest: 0.6334319\tbest: 0.6334319 (62)\ttotal: 58.7s\tremaining: 1m 21s\n",
            "63:\tlearn: 0.6374093\ttest: 0.6331687\tbest: 0.6334319 (62)\ttotal: 59.6s\tremaining: 1m 20s\n",
            "64:\tlearn: 0.6375286\ttest: 0.6332796\tbest: 0.6334319 (62)\ttotal: 1m\tremaining: 1m 19s\n",
            "65:\tlearn: 0.6375411\ttest: 0.6335073\tbest: 0.6335073 (65)\ttotal: 1m 1s\tremaining: 1m 18s\n",
            "66:\tlearn: 0.6378224\ttest: 0.6335539\tbest: 0.6335539 (66)\ttotal: 1m 2s\tremaining: 1m 17s\n",
            "67:\tlearn: 0.6378505\ttest: 0.6334626\tbest: 0.6335539 (66)\ttotal: 1m 3s\tremaining: 1m 16s\n",
            "68:\tlearn: 0.6378195\ttest: 0.6334855\tbest: 0.6335539 (66)\ttotal: 1m 4s\tremaining: 1m 15s\n",
            "69:\tlearn: 0.6378925\ttest: 0.6338641\tbest: 0.6338641 (69)\ttotal: 1m 5s\tremaining: 1m 14s\n",
            "70:\tlearn: 0.6379723\ttest: 0.6337798\tbest: 0.6338641 (69)\ttotal: 1m 6s\tremaining: 1m 13s\n",
            "71:\tlearn: 0.6380324\ttest: 0.6342273\tbest: 0.6342273 (71)\ttotal: 1m 7s\tremaining: 1m 12s\n",
            "72:\tlearn: 0.6383610\ttest: 0.6345576\tbest: 0.6345576 (72)\ttotal: 1m 7s\tremaining: 1m 11s\n",
            "73:\tlearn: 0.6385548\ttest: 0.6349854\tbest: 0.6349854 (73)\ttotal: 1m 8s\tremaining: 1m 10s\n",
            "74:\tlearn: 0.6386618\ttest: 0.6349224\tbest: 0.6349854 (73)\ttotal: 1m 9s\tremaining: 1m 9s\n",
            "75:\tlearn: 0.6387023\ttest: 0.6353182\tbest: 0.6353182 (75)\ttotal: 1m 10s\tremaining: 1m 8s\n",
            "76:\tlearn: 0.6387416\ttest: 0.6350251\tbest: 0.6353182 (75)\ttotal: 1m 11s\tremaining: 1m 7s\n",
            "77:\tlearn: 0.6389722\ttest: 0.6343093\tbest: 0.6353182 (75)\ttotal: 1m 12s\tremaining: 1m 6s\n",
            "78:\tlearn: 0.6390176\ttest: 0.6342603\tbest: 0.6353182 (75)\ttotal: 1m 13s\tremaining: 1m 5s\n",
            "79:\tlearn: 0.6391662\ttest: 0.6340870\tbest: 0.6353182 (75)\ttotal: 1m 14s\tremaining: 1m 5s\n",
            "80:\tlearn: 0.6392124\ttest: 0.6338914\tbest: 0.6353182 (75)\ttotal: 1m 15s\tremaining: 1m 4s\n",
            "81:\tlearn: 0.6393378\ttest: 0.6343247\tbest: 0.6353182 (75)\ttotal: 1m 16s\tremaining: 1m 3s\n",
            "82:\tlearn: 0.6394207\ttest: 0.6346420\tbest: 0.6353182 (75)\ttotal: 1m 17s\tremaining: 1m 2s\n",
            "83:\tlearn: 0.6398031\ttest: 0.6345911\tbest: 0.6353182 (75)\ttotal: 1m 18s\tremaining: 1m 1s\n",
            "84:\tlearn: 0.6397472\ttest: 0.6347328\tbest: 0.6353182 (75)\ttotal: 1m 18s\tremaining: 1m\n",
            "85:\tlearn: 0.6398067\ttest: 0.6347520\tbest: 0.6353182 (75)\ttotal: 1m 19s\tremaining: 59.5s\n",
            "86:\tlearn: 0.6400047\ttest: 0.6347058\tbest: 0.6353182 (75)\ttotal: 1m 20s\tremaining: 58.5s\n",
            "87:\tlearn: 0.6401388\ttest: 0.6346371\tbest: 0.6353182 (75)\ttotal: 1m 21s\tremaining: 57.6s\n",
            "88:\tlearn: 0.6401916\ttest: 0.6346450\tbest: 0.6353182 (75)\ttotal: 1m 22s\tremaining: 56.7s\n",
            "89:\tlearn: 0.6401074\ttest: 0.6345668\tbest: 0.6353182 (75)\ttotal: 1m 23s\tremaining: 55.7s\n",
            "90:\tlearn: 0.6400287\ttest: 0.6348241\tbest: 0.6353182 (75)\ttotal: 1m 24s\tremaining: 54.8s\n",
            "91:\tlearn: 0.6400594\ttest: 0.6346805\tbest: 0.6353182 (75)\ttotal: 1m 25s\tremaining: 53.9s\n",
            "92:\tlearn: 0.6403132\ttest: 0.6349740\tbest: 0.6353182 (75)\ttotal: 1m 26s\tremaining: 52.9s\n",
            "93:\tlearn: 0.6403256\ttest: 0.6349095\tbest: 0.6353182 (75)\ttotal: 1m 27s\tremaining: 52s\n",
            "94:\tlearn: 0.6403257\ttest: 0.6349037\tbest: 0.6353182 (75)\ttotal: 1m 28s\tremaining: 51.1s\n",
            "95:\tlearn: 0.6408744\ttest: 0.6355105\tbest: 0.6355105 (95)\ttotal: 1m 29s\tremaining: 50.1s\n",
            "96:\tlearn: 0.6410212\ttest: 0.6355909\tbest: 0.6355909 (96)\ttotal: 1m 30s\tremaining: 49.2s\n",
            "97:\tlearn: 0.6413163\ttest: 0.6360237\tbest: 0.6360237 (97)\ttotal: 1m 31s\tremaining: 48.3s\n",
            "98:\tlearn: 0.6414900\ttest: 0.6357432\tbest: 0.6360237 (97)\ttotal: 1m 31s\tremaining: 47.4s\n",
            "99:\tlearn: 0.6417268\ttest: 0.6357909\tbest: 0.6360237 (97)\ttotal: 1m 32s\tremaining: 46.4s\n",
            "100:\tlearn: 0.6417491\ttest: 0.6357806\tbest: 0.6360237 (97)\ttotal: 1m 33s\tremaining: 45.5s\n",
            "101:\tlearn: 0.6416283\ttest: 0.6356866\tbest: 0.6360237 (97)\ttotal: 1m 34s\tremaining: 44.6s\n",
            "102:\tlearn: 0.6417962\ttest: 0.6356927\tbest: 0.6360237 (97)\ttotal: 1m 35s\tremaining: 43.6s\n",
            "103:\tlearn: 0.6421890\ttest: 0.6357181\tbest: 0.6360237 (97)\ttotal: 1m 36s\tremaining: 42.7s\n",
            "104:\tlearn: 0.6421818\ttest: 0.6357215\tbest: 0.6360237 (97)\ttotal: 1m 37s\tremaining: 41.8s\n",
            "105:\tlearn: 0.6422261\ttest: 0.6357217\tbest: 0.6360237 (97)\ttotal: 1m 38s\tremaining: 40.8s\n",
            "106:\tlearn: 0.6423475\ttest: 0.6358044\tbest: 0.6360237 (97)\ttotal: 1m 39s\tremaining: 39.9s\n",
            "107:\tlearn: 0.6423071\ttest: 0.6357441\tbest: 0.6360237 (97)\ttotal: 1m 40s\tremaining: 39s\n",
            "108:\tlearn: 0.6424202\ttest: 0.6356310\tbest: 0.6360237 (97)\ttotal: 1m 41s\tremaining: 38.1s\n",
            "109:\tlearn: 0.6425162\ttest: 0.6359061\tbest: 0.6360237 (97)\ttotal: 1m 42s\tremaining: 37.1s\n",
            "110:\tlearn: 0.6425313\ttest: 0.6358078\tbest: 0.6360237 (97)\ttotal: 1m 43s\tremaining: 36.2s\n",
            "111:\tlearn: 0.6427129\ttest: 0.6360447\tbest: 0.6360447 (111)\ttotal: 1m 44s\tremaining: 35.3s\n",
            "112:\tlearn: 0.6427379\ttest: 0.6360611\tbest: 0.6360611 (112)\ttotal: 1m 44s\tremaining: 34.4s\n",
            "113:\tlearn: 0.6428509\ttest: 0.6358162\tbest: 0.6360611 (112)\ttotal: 1m 45s\tremaining: 33.4s\n",
            "114:\tlearn: 0.6429006\ttest: 0.6358327\tbest: 0.6360611 (112)\ttotal: 1m 46s\tremaining: 32.5s\n",
            "115:\tlearn: 0.6431042\ttest: 0.6360420\tbest: 0.6360611 (112)\ttotal: 1m 47s\tremaining: 31.6s\n",
            "116:\tlearn: 0.6431974\ttest: 0.6362498\tbest: 0.6362498 (116)\ttotal: 1m 48s\tremaining: 30.6s\n",
            "117:\tlearn: 0.6431976\ttest: 0.6364645\tbest: 0.6364645 (117)\ttotal: 1m 49s\tremaining: 29.7s\n",
            "118:\tlearn: 0.6431291\ttest: 0.6364973\tbest: 0.6364973 (118)\ttotal: 1m 50s\tremaining: 28.8s\n",
            "119:\tlearn: 0.6433279\ttest: 0.6363938\tbest: 0.6364973 (118)\ttotal: 1m 51s\tremaining: 27.9s\n",
            "120:\tlearn: 0.6433284\ttest: 0.6363214\tbest: 0.6364973 (118)\ttotal: 1m 52s\tremaining: 26.9s\n",
            "121:\tlearn: 0.6433363\ttest: 0.6364024\tbest: 0.6364973 (118)\ttotal: 1m 53s\tremaining: 26s\n",
            "122:\tlearn: 0.6434338\ttest: 0.6363378\tbest: 0.6364973 (118)\ttotal: 1m 54s\tremaining: 25.1s\n",
            "123:\tlearn: 0.6434317\ttest: 0.6362188\tbest: 0.6364973 (118)\ttotal: 1m 55s\tremaining: 24.1s\n",
            "124:\tlearn: 0.6434521\ttest: 0.6360067\tbest: 0.6364973 (118)\ttotal: 1m 56s\tremaining: 23.2s\n",
            "125:\tlearn: 0.6435304\ttest: 0.6359498\tbest: 0.6364973 (118)\ttotal: 1m 57s\tremaining: 22.3s\n",
            "126:\tlearn: 0.6435508\ttest: 0.6361205\tbest: 0.6364973 (118)\ttotal: 1m 57s\tremaining: 21.4s\n",
            "127:\tlearn: 0.6437056\ttest: 0.6363231\tbest: 0.6364973 (118)\ttotal: 1m 58s\tremaining: 20.4s\n",
            "128:\tlearn: 0.6437060\ttest: 0.6362921\tbest: 0.6364973 (118)\ttotal: 1m 59s\tremaining: 19.5s\n",
            "129:\tlearn: 0.6438242\ttest: 0.6361609\tbest: 0.6364973 (118)\ttotal: 2m\tremaining: 18.6s\n",
            "130:\tlearn: 0.6440990\ttest: 0.6358998\tbest: 0.6364973 (118)\ttotal: 2m 1s\tremaining: 17.6s\n",
            "131:\tlearn: 0.6441476\ttest: 0.6359489\tbest: 0.6364973 (118)\ttotal: 2m 2s\tremaining: 16.7s\n",
            "132:\tlearn: 0.6441298\ttest: 0.6361481\tbest: 0.6364973 (118)\ttotal: 2m 3s\tremaining: 15.8s\n",
            "133:\tlearn: 0.6441769\ttest: 0.6363809\tbest: 0.6364973 (118)\ttotal: 2m 4s\tremaining: 14.9s\n",
            "134:\tlearn: 0.6440280\ttest: 0.6364395\tbest: 0.6364973 (118)\ttotal: 2m 5s\tremaining: 13.9s\n",
            "135:\tlearn: 0.6440080\ttest: 0.6363559\tbest: 0.6364973 (118)\ttotal: 2m 6s\tremaining: 13s\n",
            "136:\tlearn: 0.6442430\ttest: 0.6364826\tbest: 0.6364973 (118)\ttotal: 2m 7s\tremaining: 12.1s\n",
            "137:\tlearn: 0.6443423\ttest: 0.6365785\tbest: 0.6365785 (137)\ttotal: 2m 8s\tremaining: 11.1s\n",
            "138:\tlearn: 0.6443737\ttest: 0.6366130\tbest: 0.6366130 (138)\ttotal: 2m 9s\tremaining: 10.2s\n",
            "139:\tlearn: 0.6446040\ttest: 0.6365284\tbest: 0.6366130 (138)\ttotal: 2m 10s\tremaining: 9.29s\n",
            "140:\tlearn: 0.6446661\ttest: 0.6362281\tbest: 0.6366130 (138)\ttotal: 2m 10s\tremaining: 8.36s\n",
            "141:\tlearn: 0.6446509\ttest: 0.6362903\tbest: 0.6366130 (138)\ttotal: 2m 11s\tremaining: 7.43s\n",
            "142:\tlearn: 0.6449246\ttest: 0.6365491\tbest: 0.6366130 (138)\ttotal: 2m 12s\tremaining: 6.5s\n",
            "143:\tlearn: 0.6449244\ttest: 0.6366389\tbest: 0.6366389 (143)\ttotal: 2m 13s\tremaining: 5.57s\n",
            "144:\tlearn: 0.6450001\ttest: 0.6366623\tbest: 0.6366623 (144)\ttotal: 2m 14s\tremaining: 4.64s\n",
            "145:\tlearn: 0.6451209\ttest: 0.6365596\tbest: 0.6366623 (144)\ttotal: 2m 15s\tremaining: 3.71s\n",
            "146:\tlearn: 0.6450906\ttest: 0.6368730\tbest: 0.6368730 (146)\ttotal: 2m 16s\tremaining: 2.79s\n",
            "147:\tlearn: 0.6452364\ttest: 0.6364439\tbest: 0.6368730 (146)\ttotal: 2m 17s\tremaining: 1.86s\n",
            "148:\tlearn: 0.6450616\ttest: 0.6367996\tbest: 0.6368730 (146)\ttotal: 2m 18s\tremaining: 929ms\n",
            "149:\tlearn: 0.6451841\ttest: 0.6367399\tbest: 0.6368730 (146)\ttotal: 2m 19s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.6368729939\n",
            "bestIteration = 146\n",
            "\n",
            "Shrink model to first 147 iterations.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7efe4b2dc050>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_prob = model_cb.predict_proba( test )\n",
        "cat_prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arY0ETB0b9bY",
        "outputId": "f4c6b386-7bc0-4057-d31a-fed201f8cbd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.59233736, 0.40766264],\n",
              "       [0.54435859, 0.45564141],\n",
              "       [0.57676357, 0.42323643],\n",
              "       ...,\n",
              "       [0.40866653, 0.59133347],\n",
              "       [0.32985868, 0.67014132],\n",
              "       [0.34732056, 0.65267944]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_cb.predict(test)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1Cxp6DdcPgL",
        "outputId": "b0352603-cd7c-430e-bcbd-9b4814fce08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#np.round(0.49931039).astype(int)\n",
        "prob=pd.DataFrame(ypred)\n",
        "prob[1] = pd.DataFrame(y_pred)\n",
        "prob[2] = pd.DataFrame(pred)\n",
        "prob['avg'] = np.round(prob.mean(axis=1)).astype(int)\n",
        "prob.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "veSlnHI5eYJi",
        "outputId": "fcc196f0-da24-4f78-d76d-65b811954694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-666de510-23a8-48c5-8d15-4c6e792fdec4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-666de510-23a8-48c5-8d15-4c6e792fdec4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-666de510-23a8-48c5-8d15-4c6e792fdec4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-666de510-23a8-48c5-8d15-4c6e792fdec4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   0  1  2  avg\n",
              "0  1  1  0    1\n",
              "1  0  0  0    0\n",
              "2  0  0  0    0\n",
              "3  0  1  0    0\n",
              "4  1  1  1    1\n",
              "5  0  0  0    0\n",
              "6  0  0  1    0\n",
              "7  0  0  0    0\n",
              "8  1  1  1    1\n",
              "9  0  0  0    0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import VotingClassifier\n",
        "# estimators=[('lgbm', lgb2), ('xgb', xgb2), ('catboost', model_cb)]\n",
        "# vclf = VotingClassifier(estimators=estimators)\n",
        "# vclf2 = vclf.fit(X_train, y_train )\n",
        "\n",
        "# from sklearn.ensemble import StackingClassifier\n",
        "# estimators=[('lgbm', lgb2), ('xgb', xgb2)]\n",
        "# sclf = StackingClassifier(estimators=estimators, final_estimator=model_cb)\n",
        "# sclf2 = sclf.fit(X_train, y_train )"
      ],
      "metadata": {
        "id": "VeI4BBqwW1vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.round(0.49931039).astype(int)"
      ],
      "metadata": {
        "id": "AXB5eCkEaoh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(\"/content/drive/MyDrive/jobcare/data/sample_submission.csv\")\n",
        "submission.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NoeflNc1UEEf",
        "outputId": "24751566-292b-4628-8dae-dca247b387ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dad2ee14-1c2a-439b-be25-06c4b373dd8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dad2ee14-1c2a-439b-be25-06c4b373dd8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dad2ee14-1c2a-439b-be25-06c4b373dd8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dad2ee14-1c2a-439b-be25-06c4b373dd8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  target\n",
              "0   0       0\n",
              "1   1       0\n",
              "2   2       0\n",
              "3   3       0\n",
              "4   4       0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission['target'] = prob['avg']\n",
        "submission.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UQeMS0pjUM_2",
        "outputId": "f0761b6e-9dba-4630-a183-c78bffeca751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-25d48f3f-6928-4ee4-9c89-db0bfccd1851\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25d48f3f-6928-4ee4-9c89-db0bfccd1851')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25d48f3f-6928-4ee4-9c89-db0bfccd1851 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25d48f3f-6928-4ee4-9c89-db0bfccd1851');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  target\n",
              "0   0       1\n",
              "1   1       0\n",
              "2   2       0\n",
              "3   3       0\n",
              "4   4       1"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"lgb+xgb+cat_mean.csv\",index=False)"
      ],
      "metadata": {
        "id": "FcOU3sj3VCsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "# score = accuracy_score(y_test, y_pred)\n",
        "# print(score)"
      ],
      "metadata": {
        "id": "GN0opjVfNW30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn0osxMzphKi"
      },
      "outputs": [],
      "source": [
        "# gs.fit(X_train, y_train, **fit_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk0Hecl7phKj"
      },
      "outputs": [],
      "source": [
        "# print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "잡케어_lgb + xgb + cat stacking",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "99dd4a7575b74e22bedc8f436cd7e7c8": {
          "model_module": "catboost-widget",
          "model_name": "CatboostWidgetModel",
          "model_module_version": "^1.0.0",
          "state": {
            "_view_name": "CatboostWidgetView",
            "_dom_classes": [],
            "_model_name": "CatboostWidgetModel",
            "data": {
              "catboost_info": {
                "content": {
                  "data": {
                    "meta": {
                      "name": "experiment",
                      "parameters": "",
                      "test_metrics": [
                        {
                          "best_value": "Max",
                          "name": "F1"
                        },
                        {
                          "best_value": "Min",
                          "name": "Logloss"
                        }
                      ],
                      "learn_sets": [
                        "learn"
                      ],
                      "launch_mode": "Train",
                      "learn_metrics": [
                        {
                          "best_value": "Max",
                          "name": "F1"
                        },
                        {
                          "best_value": "Min",
                          "name": "Logloss"
                        }
                      ],
                      "iteration_count": 150,
                      "test_sets": [
                        "test"
                      ]
                    },
                    "iterations": [
                      {
                        "test": [
                          0.6272689806,
                          0.680861353
                        ],
                        "passed_time": 1.453330336,
                        "iteration": 0,
                        "remaining_time": 216.54622,
                        "learn": [
                          0.6250642002,
                          0.6809597444
                        ]
                      },
                      {
                        "test": [
                          0.6048413352,
                          0.6740184466
                        ],
                        "passed_time": 2.745023367,
                        "iteration": 1,
                        "remaining_time": 203.1317292,
                        "learn": [
                          0.6075590141,
                          0.6743073372
                        ]
                      },
                      {
                        "test": [
                          0.6096984145,
                          0.6701497373
                        ],
                        "passed_time": 3.97045541,
                        "iteration": 2,
                        "remaining_time": 194.5523151,
                        "learn": [
                          0.6129552574,
                          0.6704615876
                        ]
                      },
                      {
                        "test": [
                          0.6107205707,
                          0.666798645
                        ],
                        "passed_time": 4.860659756,
                        "iteration": 3,
                        "remaining_time": 177.4140811,
                        "learn": [
                          0.6145074408,
                          0.6670404668
                        ]
                      },
                      {
                        "test": [
                          0.611796068,
                          0.6648874036
                        ],
                        "passed_time": 5.75327328,
                        "iteration": 4,
                        "remaining_time": 166.8449251,
                        "learn": [
                          0.6148459086,
                          0.665146411
                        ]
                      },
                      {
                        "test": [
                          0.6164479539,
                          0.6632381968
                        ],
                        "passed_time": 6.698533731,
                        "iteration": 5,
                        "remaining_time": 160.7648096,
                        "learn": [
                          0.6179860091,
                          0.6634659887
                        ]
                      },
                      {
                        "test": [
                          0.6167516056,
                          0.6620426529
                        ],
                        "passed_time": 7.60604715,
                        "iteration": 6,
                        "remaining_time": 155.3806775,
                        "learn": [
                          0.6184084485,
                          0.6623228256
                        ]
                      },
                      {
                        "test": [
                          0.6174292766,
                          0.6607063382
                        ],
                        "passed_time": 8.547374658,
                        "iteration": 7,
                        "remaining_time": 151.7159002,
                        "learn": [
                          0.6198115874,
                          0.6609175725
                        ]
                      },
                      {
                        "test": [
                          0.616864032,
                          0.6599336522
                        ],
                        "passed_time": 9.448172751,
                        "iteration": 8,
                        "remaining_time": 148.0213731,
                        "learn": [
                          0.6195517415,
                          0.6600671199
                        ]
                      },
                      {
                        "test": [
                          0.6194179367,
                          0.659338814
                        ],
                        "passed_time": 10.35545493,
                        "iteration": 9,
                        "remaining_time": 144.976369,
                        "learn": [
                          0.6208181595,
                          0.6595152438
                        ]
                      },
                      {
                        "test": [
                          0.621061816,
                          0.6586871582
                        ],
                        "passed_time": 11.27528309,
                        "iteration": 10,
                        "remaining_time": 142.4785772,
                        "learn": [
                          0.6217101697,
                          0.6588390331
                        ]
                      },
                      {
                        "test": [
                          0.6204700156,
                          0.6578885462
                        ],
                        "passed_time": 12.17338336,
                        "iteration": 11,
                        "remaining_time": 139.9939086,
                        "learn": [
                          0.6224578181,
                          0.6579745333
                        ]
                      },
                      {
                        "test": [
                          0.6234765632,
                          0.6571700847
                        ],
                        "passed_time": 13.06515734,
                        "iteration": 12,
                        "remaining_time": 137.6866582,
                        "learn": [
                          0.6240622592,
                          0.6572387224
                        ]
                      },
                      {
                        "test": [
                          0.6232926089,
                          0.6568357021
                        ],
                        "passed_time": 13.99790191,
                        "iteration": 13,
                        "remaining_time": 135.9796185,
                        "learn": [
                          0.6244225232,
                          0.6568706327
                        ]
                      },
                      {
                        "test": [
                          0.6247049567,
                          0.6562921939
                        ],
                        "passed_time": 14.90643493,
                        "iteration": 14,
                        "remaining_time": 134.1579144,
                        "learn": [
                          0.6256154151,
                          0.6562803561
                        ]
                      },
                      {
                        "test": [
                          0.6249834038,
                          0.655904743
                        ],
                        "passed_time": 15.81556044,
                        "iteration": 15,
                        "remaining_time": 132.4553187,
                        "learn": [
                          0.6258310622,
                          0.6557860207
                        ]
                      },
                      {
                        "test": [
                          0.6254884109,
                          0.6555177071
                        ],
                        "passed_time": 16.70433713,
                        "iteration": 16,
                        "remaining_time": 130.6868729,
                        "learn": [
                          0.6264748385,
                          0.6553280078
                        ]
                      },
                      {
                        "test": [
                          0.6249501415,
                          0.6553176329
                        ],
                        "passed_time": 17.59887935,
                        "iteration": 17,
                        "remaining_time": 129.0584486,
                        "learn": [
                          0.6263243665,
                          0.6550295097
                        ]
                      },
                      {
                        "test": [
                          0.6256469672,
                          0.654999793
                        ],
                        "passed_time": 18.52202038,
                        "iteration": 18,
                        "remaining_time": 127.7044563,
                        "learn": [
                          0.6263673978,
                          0.6547172878
                        ]
                      },
                      {
                        "test": [
                          0.6258566682,
                          0.6546335047
                        ],
                        "passed_time": 19.41674165,
                        "iteration": 19,
                        "remaining_time": 126.2088207,
                        "learn": [
                          0.6272310311,
                          0.6543714167
                        ]
                      },
                      {
                        "test": [
                          0.6269651854,
                          0.6544304568
                        ],
                        "passed_time": 20.32369602,
                        "iteration": 20,
                        "remaining_time": 124.8455612,
                        "learn": [
                          0.6278354987,
                          0.6541565753
                        ]
                      },
                      {
                        "test": [
                          0.6276189396,
                          0.6541503919
                        ],
                        "passed_time": 21.22070452,
                        "iteration": 21,
                        "remaining_time": 123.4659172,
                        "learn": [
                          0.6291505923,
                          0.6538209238
                        ]
                      },
                      {
                        "test": [
                          0.6289473435,
                          0.6536942922
                        ],
                        "passed_time": 22.13080988,
                        "iteration": 22,
                        "remaining_time": 122.2005589,
                        "learn": [
                          0.6296262292,
                          0.6533166566
                        ]
                      },
                      {
                        "test": [
                          0.6289596185,
                          0.653459065
                        ],
                        "passed_time": 23.02612437,
                        "iteration": 23,
                        "remaining_time": 120.887153,
                        "learn": [
                          0.629676198,
                          0.6530027836
                        ]
                      },
                      {
                        "test": [
                          0.6287490995,
                          0.6531891545
                        ],
                        "passed_time": 23.92386041,
                        "iteration": 24,
                        "remaining_time": 119.6193021,
                        "learn": [
                          0.6296669316,
                          0.6526449324
                        ]
                      },
                      {
                        "test": [
                          0.6280744022,
                          0.6529797507
                        ],
                        "passed_time": 24.83816298,
                        "iteration": 25,
                        "remaining_time": 118.4589311,
                        "learn": [
                          0.6299175078,
                          0.6524175719
                        ]
                      },
                      {
                        "test": [
                          0.6281316429,
                          0.6528899151
                        ],
                        "passed_time": 25.75316035,
                        "iteration": 26,
                        "remaining_time": 117.3199527,
                        "learn": [
                          0.6300678943,
                          0.6522685134
                        ]
                      },
                      {
                        "test": [
                          0.6278888699,
                          0.652677979
                        ],
                        "passed_time": 26.66017306,
                        "iteration": 27,
                        "remaining_time": 116.1621826,
                        "learn": [
                          0.6300047214,
                          0.6520554558
                        ]
                      },
                      {
                        "test": [
                          0.6281230407,
                          0.6524627468
                        ],
                        "passed_time": 27.60103796,
                        "iteration": 28,
                        "remaining_time": 115.1629515,
                        "learn": [
                          0.6300929851,
                          0.6518453024
                        ]
                      },
                      {
                        "test": [
                          0.6286392105,
                          0.6522629524
                        ],
                        "passed_time": 28.51881301,
                        "iteration": 29,
                        "remaining_time": 114.075252,
                        "learn": [
                          0.6305559492,
                          0.6516081861
                        ]
                      },
                      {
                        "test": [
                          0.6295653493,
                          0.6520933619
                        ],
                        "passed_time": 29.44487426,
                        "iteration": 30,
                        "remaining_time": 113.0303238,
                        "learn": [
                          0.6309273286,
                          0.6513813646
                        ]
                      },
                      {
                        "test": [
                          0.6296552705,
                          0.6519398467
                        ],
                        "passed_time": 30.38209676,
                        "iteration": 31,
                        "remaining_time": 112.0339818,
                        "learn": [
                          0.6310626883,
                          0.6511812282
                        ]
                      },
                      {
                        "test": [
                          0.6288527519,
                          0.6517423908
                        ],
                        "passed_time": 31.31667233,
                        "iteration": 32,
                        "remaining_time": 111.0318383,
                        "learn": [
                          0.6307222306,
                          0.650929026
                        ]
                      },
                      {
                        "test": [
                          0.62900174,
                          0.6516051013
                        ],
                        "passed_time": 32.25171322,
                        "iteration": 33,
                        "remaining_time": 110.0352569,
                        "learn": [
                          0.6307417819,
                          0.6507465643
                        ]
                      },
                      {
                        "test": [
                          0.6292835483,
                          0.6513428633
                        ],
                        "passed_time": 33.15338987,
                        "iteration": 34,
                        "remaining_time": 108.9325667,
                        "learn": [
                          0.6309534515,
                          0.6504677591
                        ]
                      },
                      {
                        "test": [
                          0.6291974551,
                          0.6512357171
                        ],
                        "passed_time": 34.07778227,
                        "iteration": 35,
                        "remaining_time": 107.9129772,
                        "learn": [
                          0.6309676839,
                          0.6503386861
                        ]
                      },
                      {
                        "test": [
                          0.6299010766,
                          0.6510633469
                        ],
                        "passed_time": 34.99061713,
                        "iteration": 36,
                        "remaining_time": 106.8632361,
                        "learn": [
                          0.6320137515,
                          0.6501226641
                        ]
                      },
                      {
                        "test": [
                          0.6302004691,
                          0.6509590479
                        ],
                        "passed_time": 35.91651082,
                        "iteration": 37,
                        "remaining_time": 105.8591898,
                        "learn": [
                          0.6318755145,
                          0.6499817774
                        ]
                      },
                      {
                        "test": [
                          0.6301723729,
                          0.6507726264
                        ],
                        "passed_time": 36.79587749,
                        "iteration": 38,
                        "remaining_time": 104.7267283,
                        "learn": [
                          0.631839713,
                          0.6497922391
                        ]
                      },
                      {
                        "test": [
                          0.6302785137,
                          0.6507362424
                        ],
                        "passed_time": 37.71422495,
                        "iteration": 39,
                        "remaining_time": 103.7141186,
                        "learn": [
                          0.6321099832,
                          0.6497036406
                        ]
                      },
                      {
                        "test": [
                          0.6300839251,
                          0.6506491862
                        ],
                        "passed_time": 38.61749458,
                        "iteration": 40,
                        "remaining_time": 102.6660222,
                        "learn": [
                          0.6320792229,
                          0.6495504914
                        ]
                      },
                      {
                        "test": [
                          0.6303510802,
                          0.6505709169
                        ],
                        "passed_time": 39.53846414,
                        "iteration": 41,
                        "remaining_time": 101.6703364,
                        "learn": [
                          0.632206449,
                          0.6494303653
                        ]
                      },
                      {
                        "test": [
                          0.6301479105,
                          0.6504110145
                        ],
                        "passed_time": 40.42529888,
                        "iteration": 42,
                        "remaining_time": 100.5931856,
                        "learn": [
                          0.6322624647,
                          0.6492540387
                        ]
                      },
                      {
                        "test": [
                          0.6302667806,
                          0.6504058294
                        ],
                        "passed_time": 41.35792169,
                        "iteration": 43,
                        "remaining_time": 99.63499317,
                        "learn": [
                          0.6324217566,
                          0.6491538814
                        ]
                      },
                      {
                        "test": [
                          0.630053742,
                          0.6503649529
                        ],
                        "passed_time": 42.26947938,
                        "iteration": 44,
                        "remaining_time": 98.62878522,
                        "learn": [
                          0.6325838492,
                          0.6490368727
                        ]
                      },
                      {
                        "test": [
                          0.6299946825,
                          0.6503303481
                        ],
                        "passed_time": 43.20002294,
                        "iteration": 45,
                        "remaining_time": 97.66961709,
                        "learn": [
                          0.6326163262,
                          0.6489725718
                        ]
                      },
                      {
                        "test": [
                          0.630134645,
                          0.6502720339
                        ],
                        "passed_time": 44.12778368,
                        "iteration": 46,
                        "remaining_time": 96.70556848,
                        "learn": [
                          0.6327422415,
                          0.6488540701
                        ]
                      },
                      {
                        "test": [
                          0.6306176309,
                          0.6501206223
                        ],
                        "passed_time": 45.05033086,
                        "iteration": 47,
                        "remaining_time": 95.73195308,
                        "learn": [
                          0.6331086185,
                          0.6486331984
                        ]
                      },
                      {
                        "test": [
                          0.6309333941,
                          0.6498647513
                        ],
                        "passed_time": 45.93631879,
                        "iteration": 48,
                        "remaining_time": 94.68506526,
                        "learn": [
                          0.6334593362,
                          0.6483542499
                        ]
                      },
                      {
                        "test": [
                          0.6315589714,
                          0.6497987501
                        ],
                        "passed_time": 46.84676109,
                        "iteration": 49,
                        "remaining_time": 93.69352218,
                        "learn": [
                          0.6340331523,
                          0.6481794527
                        ]
                      },
                      {
                        "test": [
                          0.6318266348,
                          0.6496302351
                        ],
                        "passed_time": 47.78433066,
                        "iteration": 50,
                        "remaining_time": 92.75781835,
                        "learn": [
                          0.6341021327,
                          0.6479989904
                        ]
                      },
                      {
                        "test": [
                          0.6321684163,
                          0.649483019
                        ],
                        "passed_time": 48.67408426,
                        "iteration": 51,
                        "remaining_time": 91.73192803,
                        "learn": [
                          0.6342996427,
                          0.647802502
                        ]
                      },
                      {
                        "test": [
                          0.6319038213,
                          0.6493712636
                        ],
                        "passed_time": 49.60250086,
                        "iteration": 52,
                        "remaining_time": 90.78193553,
                        "learn": [
                          0.6343702652,
                          0.6476381751
                        ]
                      },
                      {
                        "test": [
                          0.6316859333,
                          0.649313529
                        ],
                        "passed_time": 50.51192009,
                        "iteration": 53,
                        "remaining_time": 89.79896906,
                        "learn": [
                          0.6346946457,
                          0.6475341604
                        ]
                      },
                      {
                        "test": [
                          0.6314758463,
                          0.6490916451
                        ],
                        "passed_time": 51.40408729,
                        "iteration": 54,
                        "remaining_time": 88.78887804,
                        "learn": [
                          0.6347092408,
                          0.6472898736
                        ]
                      },
                      {
                        "test": [
                          0.6317808844,
                          0.6488271296
                        ],
                        "passed_time": 52.32053226,
                        "iteration": 55,
                        "remaining_time": 87.82375058,
                        "learn": [
                          0.6350456205,
                          0.647021522
                        ]
                      },
                      {
                        "test": [
                          0.6320824554,
                          0.6487539913
                        ],
                        "passed_time": 53.24426707,
                        "iteration": 56,
                        "remaining_time": 86.87222522,
                        "learn": [
                          0.6356536326,
                          0.6468656006
                        ]
                      },
                      {
                        "test": [
                          0.6329551061,
                          0.6486869218
                        ],
                        "passed_time": 54.13720596,
                        "iteration": 57,
                        "remaining_time": 85.87280945,
                        "learn": [
                          0.6362214635,
                          0.6466978676
                        ]
                      },
                      {
                        "test": [
                          0.6333023644,
                          0.6485673713
                        ],
                        "passed_time": 55.08033321,
                        "iteration": 58,
                        "remaining_time": 84.95441223,
                        "learn": [
                          0.6363494451,
                          0.6465177122
                        ]
                      },
                      {
                        "test": [
                          0.6328316283,
                          0.648548452
                        ],
                        "passed_time": 56.00422746,
                        "iteration": 59,
                        "remaining_time": 84.00634119,
                        "learn": [
                          0.6364333381,
                          0.6464300294
                        ]
                      },
                      {
                        "test": [
                          0.632933007,
                          0.648439849
                        ],
                        "passed_time": 56.87328945,
                        "iteration": 60,
                        "remaining_time": 82.97906166,
                        "learn": [
                          0.6368467377,
                          0.6462539848
                        ]
                      },
                      {
                        "test": [
                          0.6328955479,
                          0.6483108425
                        ],
                        "passed_time": 57.80650498,
                        "iteration": 61,
                        "remaining_time": 82.04794256,
                        "learn": [
                          0.6369488839,
                          0.6461012093
                        ]
                      },
                      {
                        "test": [
                          0.633431919,
                          0.6482799433
                        ],
                        "passed_time": 58.71699245,
                        "iteration": 62,
                        "remaining_time": 81.08537052,
                        "learn": [
                          0.637116309,
                          0.6459962632
                        ]
                      },
                      {
                        "test": [
                          0.6331686876,
                          0.6481369608
                        ],
                        "passed_time": 59.6149037,
                        "iteration": 63,
                        "remaining_time": 80.10752685,
                        "learn": [
                          0.6374093299,
                          0.6457915334
                        ]
                      },
                      {
                        "test": [
                          0.633279575,
                          0.647978869
                        ],
                        "passed_time": 60.55361784,
                        "iteration": 64,
                        "remaining_time": 79.18550025,
                        "learn": [
                          0.6375285695,
                          0.6456020039
                        ]
                      },
                      {
                        "test": [
                          0.6335072574,
                          0.6479381938
                        ],
                        "passed_time": 61.47931785,
                        "iteration": 65,
                        "remaining_time": 78.24640454,
                        "learn": [
                          0.6375411043,
                          0.6455114536
                        ]
                      },
                      {
                        "test": [
                          0.6335539165,
                          0.6479164797
                        ],
                        "passed_time": 62.40134583,
                        "iteration": 66,
                        "remaining_time": 77.30315976,
                        "learn": [
                          0.6378224391,
                          0.6454559365
                        ]
                      },
                      {
                        "test": [
                          0.6334626217,
                          0.6479027292
                        ],
                        "passed_time": 63.33154368,
                        "iteration": 67,
                        "remaining_time": 76.37039091,
                        "learn": [
                          0.6378505005,
                          0.6454017251
                        ]
                      },
                      {
                        "test": [
                          0.6334854508,
                          0.647858032
                        ],
                        "passed_time": 64.26067356,
                        "iteration": 68,
                        "remaining_time": 75.43644288,
                        "learn": [
                          0.6378194659,
                          0.6453228814
                        ]
                      },
                      {
                        "test": [
                          0.63386413,
                          0.6478375684
                        ],
                        "passed_time": 65.19041245,
                        "iteration": 69,
                        "remaining_time": 74.50332851,
                        "learn": [
                          0.6378924696,
                          0.645196411
                        ]
                      },
                      {
                        "test": [
                          0.6337798353,
                          0.6477758427
                        ],
                        "passed_time": 66.10156043,
                        "iteration": 70,
                        "remaining_time": 73.54962358,
                        "learn": [
                          0.6379723345,
                          0.64506437
                        ]
                      },
                      {
                        "test": [
                          0.6342272969,
                          0.6477298834
                        ],
                        "passed_time": 67.02693064,
                        "iteration": 71,
                        "remaining_time": 72.61250819,
                        "learn": [
                          0.6380324253,
                          0.644960295
                        ]
                      },
                      {
                        "test": [
                          0.6345575754,
                          0.6476264364
                        ],
                        "passed_time": 67.92392995,
                        "iteration": 72,
                        "remaining_time": 71.64578912,
                        "learn": [
                          0.6383610072,
                          0.6447820695
                        ]
                      },
                      {
                        "test": [
                          0.6349853509,
                          0.647495099
                        ],
                        "passed_time": 68.8140761,
                        "iteration": 73,
                        "remaining_time": 70.673916,
                        "learn": [
                          0.6385548441,
                          0.6446301265
                        ]
                      },
                      {
                        "test": [
                          0.6349224409,
                          0.647425444
                        ],
                        "passed_time": 69.73566944,
                        "iteration": 74,
                        "remaining_time": 69.73566944,
                        "learn": [
                          0.6386618262,
                          0.6445260856
                        ]
                      },
                      {
                        "test": [
                          0.635318209,
                          0.6473713859
                        ],
                        "passed_time": 70.64941481,
                        "iteration": 75,
                        "remaining_time": 68.79021969,
                        "learn": [
                          0.6387023179,
                          0.6443958341
                        ]
                      },
                      {
                        "test": [
                          0.6350251399,
                          0.6473444752
                        ],
                        "passed_time": 71.57799614,
                        "iteration": 76,
                        "remaining_time": 67.85965868,
                        "learn": [
                          0.6387416207,
                          0.644340456
                        ]
                      },
                      {
                        "test": [
                          0.6343093057,
                          0.6472546229
                        ],
                        "passed_time": 72.49942637,
                        "iteration": 77,
                        "remaining_time": 66.92254742,
                        "learn": [
                          0.6389721871,
                          0.6441244682
                        ]
                      },
                      {
                        "test": [
                          0.6342603146,
                          0.6471391588
                        ],
                        "passed_time": 73.4257498,
                        "iteration": 78,
                        "remaining_time": 65.99023084,
                        "learn": [
                          0.6390175672,
                          0.6439591185
                        ]
                      },
                      {
                        "test": [
                          0.6340870226,
                          0.6471237857
                        ],
                        "passed_time": 74.36021788,
                        "iteration": 79,
                        "remaining_time": 65.06519065,
                        "learn": [
                          0.6391662142,
                          0.6439234791
                        ]
                      },
                      {
                        "test": [
                          0.6338914122,
                          0.6470610119
                        ],
                        "passed_time": 75.26952721,
                        "iteration": 80,
                        "remaining_time": 64.11848614,
                        "learn": [
                          0.6392124132,
                          0.6437953843
                        ]
                      },
                      {
                        "test": [
                          0.6343247428,
                          0.647060782
                        ],
                        "passed_time": 76.18655413,
                        "iteration": 81,
                        "remaining_time": 63.17909367,
                        "learn": [
                          0.6393377706,
                          0.6437255542
                        ]
                      },
                      {
                        "test": [
                          0.6346420499,
                          0.6470156893
                        ],
                        "passed_time": 77.11323268,
                        "iteration": 82,
                        "remaining_time": 62.2480312,
                        "learn": [
                          0.6394207173,
                          0.6436406497
                        ]
                      },
                      {
                        "test": [
                          0.6345910934,
                          0.6469963284
                        ],
                        "passed_time": 78.03244237,
                        "iteration": 83,
                        "remaining_time": 61.31120472,
                        "learn": [
                          0.6398031462,
                          0.643567083
                        ]
                      },
                      {
                        "test": [
                          0.6347328136,
                          0.647025535
                        ],
                        "passed_time": 78.96630172,
                        "iteration": 84,
                        "remaining_time": 60.38599543,
                        "learn": [
                          0.6397471794,
                          0.6434688695
                        ]
                      },
                      {
                        "test": [
                          0.6347520426,
                          0.6470157051
                        ],
                        "passed_time": 79.89343628,
                        "iteration": 85,
                        "remaining_time": 59.45558049,
                        "learn": [
                          0.6398067069,
                          0.6434187291
                        ]
                      },
                      {
                        "test": [
                          0.6347058432,
                          0.6469284212
                        ],
                        "passed_time": 80.82517693,
                        "iteration": 86,
                        "remaining_time": 58.5285764,
                        "learn": [
                          0.6400047427,
                          0.6432923319
                        ]
                      },
                      {
                        "test": [
                          0.6346371263,
                          0.6469269402
                        ],
                        "passed_time": 81.7453534,
                        "iteration": 87,
                        "remaining_time": 57.59331717,
                        "learn": [
                          0.6401388349,
                          0.643262517
                        ]
                      },
                      {
                        "test": [
                          0.6346449811,
                          0.6469137643
                        ],
                        "passed_time": 82.67418812,
                        "iteration": 88,
                        "remaining_time": 56.66433118,
                        "learn": [
                          0.6401915577,
                          0.6432300296
                        ]
                      },
                      {
                        "test": [
                          0.634566775,
                          0.6469119688
                        ],
                        "passed_time": 83.60119473,
                        "iteration": 89,
                        "remaining_time": 55.73412982,
                        "learn": [
                          0.6401073627,
                          0.6431952168
                        ]
                      },
                      {
                        "test": [
                          0.6348240929,
                          0.6468629134
                        ],
                        "passed_time": 84.53264062,
                        "iteration": 90,
                        "remaining_time": 54.80687689,
                        "learn": [
                          0.6400286508,
                          0.643101869
                        ]
                      },
                      {
                        "test": [
                          0.6346804547,
                          0.6468589023
                        ],
                        "passed_time": 85.44661532,
                        "iteration": 91,
                        "remaining_time": 53.86851835,
                        "learn": [
                          0.6400593908,
                          0.6430948384
                        ]
                      },
                      {
                        "test": [
                          0.6349740489,
                          0.6466721856
                        ],
                        "passed_time": 86.36989535,
                        "iteration": 92,
                        "remaining_time": 52.93638747,
                        "learn": [
                          0.6403132044,
                          0.642885639
                        ]
                      },
                      {
                        "test": [
                          0.6349094644,
                          0.6466633656
                        ],
                        "passed_time": 87.30409958,
                        "iteration": 93,
                        "remaining_time": 52.01095294,
                        "learn": [
                          0.6403255659,
                          0.6428632835
                        ]
                      },
                      {
                        "test": [
                          0.6349037319,
                          0.6466613312
                        ],
                        "passed_time": 88.24311045,
                        "iteration": 94,
                        "remaining_time": 51.08811657,
                        "learn": [
                          0.6403257341,
                          0.642842494
                        ]
                      },
                      {
                        "test": [
                          0.6355104677,
                          0.6465218713
                        ],
                        "passed_time": 89.13749799,
                        "iteration": 95,
                        "remaining_time": 50.13984262,
                        "learn": [
                          0.6408743656,
                          0.6426562357
                        ]
                      },
                      {
                        "test": [
                          0.6355908862,
                          0.6465079754
                        ],
                        "passed_time": 90.07793161,
                        "iteration": 96,
                        "remaining_time": 49.21783892,
                        "learn": [
                          0.6410212048,
                          0.6426180672
                        ]
                      },
                      {
                        "test": [
                          0.6360236893,
                          0.6464306667
                        ],
                        "passed_time": 91.00500901,
                        "iteration": 97,
                        "remaining_time": 48.28837213,
                        "learn": [
                          0.6413163278,
                          0.6425151982
                        ]
                      },
                      {
                        "test": [
                          0.6357432349,
                          0.6463594912
                        ],
                        "passed_time": 91.93560272,
                        "iteration": 98,
                        "remaining_time": 47.36076504,
                        "learn": [
                          0.6414900249,
                          0.6424096258
                        ]
                      },
                      {
                        "test": [
                          0.635790872,
                          0.6463327777
                        ],
                        "passed_time": 92.85879375,
                        "iteration": 99,
                        "remaining_time": 46.42939687,
                        "learn": [
                          0.6417267688,
                          0.6423256135
                        ]
                      },
                      {
                        "test": [
                          0.6357805651,
                          0.646332615
                        ],
                        "passed_time": 93.79605653,
                        "iteration": 100,
                        "remaining_time": 45.50501752,
                        "learn": [
                          0.6417490525,
                          0.6423162363
                        ]
                      },
                      {
                        "test": [
                          0.6356865684,
                          0.6463256377
                        ],
                        "passed_time": 94.71272076,
                        "iteration": 101,
                        "remaining_time": 44.57069212,
                        "learn": [
                          0.6416283072,
                          0.6422592706
                        ]
                      },
                      {
                        "test": [
                          0.6356927397,
                          0.6463309722
                        ],
                        "passed_time": 95.62726451,
                        "iteration": 102,
                        "remaining_time": 43.63574206,
                        "learn": [
                          0.6417962446,
                          0.6422222287
                        ]
                      },
                      {
                        "test": [
                          0.6357181454,
                          0.6462396241
                        ],
                        "passed_time": 96.55368233,
                        "iteration": 103,
                        "remaining_time": 42.70643641,
                        "learn": [
                          0.6421889694,
                          0.642080638
                        ]
                      },
                      {
                        "test": [
                          0.6357215317,
                          0.6462225602
                        ],
                        "passed_time": 97.47998145,
                        "iteration": 104,
                        "remaining_time": 41.77713491,
                        "learn": [
                          0.6421817958,
                          0.64202772
                        ]
                      },
                      {
                        "test": [
                          0.6357216656,
                          0.6462120542
                        ],
                        "passed_time": 98.41015711,
                        "iteration": 105,
                        "remaining_time": 40.84949918,
                        "learn": [
                          0.6422260856,
                          0.6419971284
                        ]
                      },
                      {
                        "test": [
                          0.6358044,
                          0.6462024602
                        ],
                        "passed_time": 99.34095571,
                        "iteration": 106,
                        "remaining_time": 39.92206631,
                        "learn": [
                          0.6423475237,
                          0.641955874
                        ]
                      },
                      {
                        "test": [
                          0.6357441404,
                          0.6462122486
                        ],
                        "passed_time": 100.2740805,
                        "iteration": 107,
                        "remaining_time": 38.99547577,
                        "learn": [
                          0.6423070637,
                          0.6419342007
                        ]
                      },
                      {
                        "test": [
                          0.6356309851,
                          0.6461976
                        ],
                        "passed_time": 101.2112577,
                        "iteration": 108,
                        "remaining_time": 38.07028961,
                        "learn": [
                          0.6424202222,
                          0.6418821962
                        ]
                      },
                      {
                        "test": [
                          0.635906088,
                          0.64616413
                        ],
                        "passed_time": 102.1412526,
                        "iteration": 109,
                        "remaining_time": 37.14227369,
                        "learn": [
                          0.6425161631,
                          0.6418176051
                        ]
                      },
                      {
                        "test": [
                          0.635807794,
                          0.6461496648
                        ],
                        "passed_time": 103.0636839,
                        "iteration": 110,
                        "remaining_time": 36.21156461,
                        "learn": [
                          0.6425312786,
                          0.6417581654
                        ]
                      },
                      {
                        "test": [
                          0.6360447478,
                          0.6461018648
                        ],
                        "passed_time": 104.0006143,
                        "iteration": 111,
                        "remaining_time": 35.28592273,
                        "learn": [
                          0.6427128502,
                          0.6416796089
                        ]
                      },
                      {
                        "test": [
                          0.6360610974,
                          0.6461014063
                        ],
                        "passed_time": 104.910643,
                        "iteration": 112,
                        "remaining_time": 34.35127248,
                        "learn": [
                          0.6427378846,
                          0.6416548321
                        ]
                      },
                      {
                        "test": [
                          0.6358162249,
                          0.6460678925
                        ],
                        "passed_time": 105.8310982,
                        "iteration": 113,
                        "remaining_time": 33.42034681,
                        "learn": [
                          0.6428508833,
                          0.6415763662
                        ]
                      },
                      {
                        "test": [
                          0.6358326696,
                          0.6460413601
                        ],
                        "passed_time": 106.7679306,
                        "iteration": 114,
                        "remaining_time": 32.49458758,
                        "learn": [
                          0.6429006227,
                          0.6414970666
                        ]
                      },
                      {
                        "test": [
                          0.6360420006,
                          0.6459514005
                        ],
                        "passed_time": 107.7017789,
                        "iteration": 115,
                        "remaining_time": 31.5677628,
                        "learn": [
                          0.6431041998,
                          0.6413908614
                        ]
                      },
                      {
                        "test": [
                          0.636249834,
                          0.6459164618
                        ],
                        "passed_time": 108.6230522,
                        "iteration": 116,
                        "remaining_time": 30.63727115,
                        "learn": [
                          0.6431974377,
                          0.6413206764
                        ]
                      },
                      {
                        "test": [
                          0.6364645076,
                          0.645888344
                        ],
                        "passed_time": 109.5569979,
                        "iteration": 117,
                        "remaining_time": 29.71037232,
                        "learn": [
                          0.643197627,
                          0.6412690956
                        ]
                      },
                      {
                        "test": [
                          0.636497292,
                          0.6458828099
                        ],
                        "passed_time": 110.4857665,
                        "iteration": 118,
                        "remaining_time": 28.7820064,
                        "learn": [
                          0.6431291153,
                          0.6412471751
                        ]
                      },
                      {
                        "test": [
                          0.6363938064,
                          0.6458701796
                        ],
                        "passed_time": 111.4207802,
                        "iteration": 119,
                        "remaining_time": 27.85519506,
                        "learn": [
                          0.6433278536,
                          0.6411992094
                        ]
                      },
                      {
                        "test": [
                          0.6363213944,
                          0.6458653805
                        ],
                        "passed_time": 112.360952,
                        "iteration": 120,
                        "remaining_time": 26.92948436,
                        "learn": [
                          0.6433283824,
                          0.6411729548
                        ]
                      },
                      {
                        "test": [
                          0.6364024315,
                          0.6458569639
                        ],
                        "passed_time": 113.2935272,
                        "iteration": 121,
                        "remaining_time": 26.00179312,
                        "learn": [
                          0.6433363021,
                          0.6411324705
                        ]
                      },
                      {
                        "test": [
                          0.6363377663,
                          0.6458474756
                        ],
                        "passed_time": 114.2166099,
                        "iteration": 122,
                        "remaining_time": 25.07193875,
                        "learn": [
                          0.6434338074,
                          0.6410928406
                        ]
                      },
                      {
                        "test": [
                          0.6362187696,
                          0.645836493
                        ],
                        "passed_time": 115.1363136,
                        "iteration": 123,
                        "remaining_time": 24.14148512,
                        "learn": [
                          0.6434316608,
                          0.6410469157
                        ]
                      },
                      {
                        "test": [
                          0.636006677,
                          0.6458246259
                        ],
                        "passed_time": 116.0668152,
                        "iteration": 124,
                        "remaining_time": 23.21336304,
                        "learn": [
                          0.6434520989,
                          0.6409886245
                        ]
                      },
                      {
                        "test": [
                          0.6359497705,
                          0.6457785474
                        ],
                        "passed_time": 117.0026548,
                        "iteration": 125,
                        "remaining_time": 22.28621997,
                        "learn": [
                          0.6435303732,
                          0.6409240526
                        ]
                      },
                      {
                        "test": [
                          0.6361204902,
                          0.6457113768
                        ],
                        "passed_time": 117.9353629,
                        "iteration": 126,
                        "remaining_time": 21.35837281,
                        "learn": [
                          0.6435507753,
                          0.6408464336
                        ]
                      },
                      {
                        "test": [
                          0.6363231124,
                          0.6456842703
                        ],
                        "passed_time": 118.8571425,
                        "iteration": 127,
                        "remaining_time": 20.42857136,
                        "learn": [
                          0.6437055532,
                          0.6407669078
                        ]
                      },
                      {
                        "test": [
                          0.6362920741,
                          0.6456850835
                        ],
                        "passed_time": 119.8022159,
                        "iteration": 128,
                        "remaining_time": 19.50268631,
                        "learn": [
                          0.6437060427,
                          0.6407655754
                        ]
                      },
                      {
                        "test": [
                          0.6361609472,
                          0.6456609451
                        ],
                        "passed_time": 120.738088,
                        "iteration": 129,
                        "remaining_time": 18.57509047,
                        "learn": [
                          0.6438242255,
                          0.6407078307
                        ]
                      },
                      {
                        "test": [
                          0.6358997705,
                          0.64566014
                        ],
                        "passed_time": 121.668657,
                        "iteration": 130,
                        "remaining_time": 17.64659911,
                        "learn": [
                          0.6440989537,
                          0.6406200127
                        ]
                      },
                      {
                        "test": [
                          0.6359488965,
                          0.6456547773
                        ],
                        "passed_time": 122.6070521,
                        "iteration": 131,
                        "remaining_time": 16.71914347,
                        "learn": [
                          0.6441476119,
                          0.6405984208
                        ]
                      },
                      {
                        "test": [
                          0.6361481425,
                          0.6456415842
                        ],
                        "passed_time": 123.5388795,
                        "iteration": 132,
                        "remaining_time": 15.79068385,
                        "learn": [
                          0.6441297916,
                          0.6405598913
                        ]
                      },
                      {
                        "test": [
                          0.6363808765,
                          0.6456155624
                        ],
                        "passed_time": 124.4635345,
                        "iteration": 133,
                        "remaining_time": 14.86131755,
                        "learn": [
                          0.6441769237,
                          0.6404777474
                        ]
                      },
                      {
                        "test": [
                          0.6364395046,
                          0.6455659487
                        ],
                        "passed_time": 125.3800345,
                        "iteration": 134,
                        "remaining_time": 13.93111494,
                        "learn": [
                          0.6440280365,
                          0.6404041053
                        ]
                      },
                      {
                        "test": [
                          0.6363558767,
                          0.6455533846
                        ],
                        "passed_time": 126.306605,
                        "iteration": 135,
                        "remaining_time": 13.00215051,
                        "learn": [
                          0.6440080373,
                          0.6403760566
                        ]
                      },
                      {
                        "test": [
                          0.6364826409,
                          0.6455162419
                        ],
                        "passed_time": 127.243735,
                        "iteration": 136,
                        "remaining_time": 12.07422303,
                        "learn": [
                          0.6442429814,
                          0.6402925507
                        ]
                      },
                      {
                        "test": [
                          0.6365784903,
                          0.6454308637
                        ],
                        "passed_time": 128.17135,
                        "iteration": 137,
                        "remaining_time": 11.14533478,
                        "learn": [
                          0.6443423214,
                          0.6401799952
                        ]
                      },
                      {
                        "test": [
                          0.6366129813,
                          0.6454087046
                        ],
                        "passed_time": 129.1082181,
                        "iteration": 138,
                        "remaining_time": 10.21719712,
                        "learn": [
                          0.6443736579,
                          0.6401301529
                        ]
                      },
                      {
                        "test": [
                          0.6365284409,
                          0.6453917649
                        ],
                        "passed_time": 130.0351526,
                        "iteration": 139,
                        "remaining_time": 9.288225189,
                        "learn": [
                          0.6446040028,
                          0.6401047335
                        ]
                      },
                      {
                        "test": [
                          0.6362281276,
                          0.6453338263
                        ],
                        "passed_time": 130.9704831,
                        "iteration": 140,
                        "remaining_time": 8.359818072,
                        "learn": [
                          0.6446660677,
                          0.6399623327
                        ]
                      },
                      {
                        "test": [
                          0.6362902996,
                          0.645323715
                        ],
                        "passed_time": 131.8989924,
                        "iteration": 141,
                        "remaining_time": 7.430929151,
                        "learn": [
                          0.6446508607,
                          0.6399026839
                        ]
                      },
                      {
                        "test": [
                          0.6365491387,
                          0.6452869078
                        ],
                        "passed_time": 132.8312155,
                        "iteration": 142,
                        "remaining_time": 6.502227332,
                        "learn": [
                          0.6449245821,
                          0.6398019719
                        ]
                      },
                      {
                        "test": [
                          0.6366389171,
                          0.645273695
                        ],
                        "passed_time": 133.7567954,
                        "iteration": 143,
                        "remaining_time": 5.573199809,
                        "learn": [
                          0.6449243927,
                          0.6397565605
                        ]
                      },
                      {
                        "test": [
                          0.6366622989,
                          0.6452617787
                        ],
                        "passed_time": 134.6630559,
                        "iteration": 144,
                        "remaining_time": 4.643553652,
                        "learn": [
                          0.645000083,
                          0.6396960978
                        ]
                      },
                      {
                        "test": [
                          0.636559589,
                          0.6452501734
                        ],
                        "passed_time": 135.5914348,
                        "iteration": 145,
                        "remaining_time": 3.714833829,
                        "learn": [
                          0.6451209104,
                          0.6396347656
                        ]
                      },
                      {
                        "test": [
                          0.6368729939,
                          0.645235725
                        ],
                        "passed_time": 136.5248125,
                        "iteration": 146,
                        "remaining_time": 2.786220664,
                        "learn": [
                          0.6450906194,
                          0.6395544653
                        ]
                      },
                      {
                        "test": [
                          0.6364439211,
                          0.6452000528
                        ],
                        "passed_time": 137.4540551,
                        "iteration": 147,
                        "remaining_time": 1.857487231,
                        "learn": [
                          0.645236385,
                          0.6394677325
                        ]
                      },
                      {
                        "test": [
                          0.6367995746,
                          0.6451955879
                        ],
                        "passed_time": 138.4027919,
                        "iteration": 148,
                        "remaining_time": 0.9288777978,
                        "learn": [
                          0.6450615747,
                          0.6394425648
                        ]
                      },
                      {
                        "test": [
                          0.6367398857,
                          0.6451512602
                        ],
                        "passed_time": 139.3349911,
                        "iteration": 149,
                        "remaining_time": 0,
                        "learn": [
                          0.6451840772,
                          0.6393775164
                        ]
                      }
                    ]
                  },
                  "total_iterations": 150,
                  "passed_iterations": 149
                },
                "path": "catboost_info",
                "name": "catboost_info"
              }
            },
            "_view_module": "catboost-widget",
            "_model_module_version": "^1.0.0",
            "_view_count": null,
            "_view_module_version": "^1.0.0",
            "layout": "IPY_MODEL_b538a48a11ea468a9871fbef89cd5cf9",
            "_model_module": "catboost-widget"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
